# -*- coding: utf-8 -*-
from __future__ import annotations

import datetime
import json
import re
import shutil
import os
import random
import requests
import time
import uuid
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional

# [ìˆ˜ì •] ê°•ë ¥í•œ ì˜¤ë””ì˜¤ ì¸¡ì • í•¨ìˆ˜(audio_duration_sec) ì‚¬ìš©
from app.utils import (
    AI,
    load_json,
    save_json,
    ensure_dir
)
from app import settings
from app.video_build import build_shots_with_i2v, concatenate_scene_clips, fill_prompt_movie_with_ai
from app.audio_sync import get_audio_duration

def _now_str() -> str:
    return datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")


# -----------------------------------------------------------------------------
# [New] ComfyUI ì œì¶œ ë° ëŒ€ê¸° í•¨ìˆ˜ (ë…ë¦½í˜•)
# -----------------------------------------------------------------------------
def _submit_and_wait_local(
        base_url: str,
        graph: dict,
        timeout: int = 900,
        poll: float = 2.0,
        on_progress: Optional[Callable[[Dict[str, Any]], None]] = None
) -> dict:
    """ComfyUI ì›Œí¬í”Œë¡œìš° ì œì¶œ ë° ëŒ€ê¸°"""
    client_id = str(uuid.uuid4())
    payload = {"prompt": graph, "client_id": client_id}

    try:
        resp = requests.post(f"{base_url}/prompt", json=payload, timeout=30)
        resp.raise_for_status()
        prompt_id = resp.json().get("prompt_id")
    except Exception as e:
        raise RuntimeError(f"ComfyUI ì œì¶œ ì‹¤íŒ¨: {e}")

    start_t = time.time()
    while True:
        elapsed = time.time() - start_t
        if elapsed > timeout:
            raise TimeoutError(f"ComfyUI ì‹œê°„ ì´ˆê³¼ ({elapsed:.1f}s)")

        try:
            h_resp = requests.get(f"{base_url}/history/{prompt_id}", timeout=10)
            if h_resp.status_code == 200:
                h_data = h_resp.json()
                if prompt_id in h_data:
                    return h_data[prompt_id]
        except Exception:
            pass
        time.sleep(poll)


# -----------------------------------------------------------------------------
# 1. Zonos TTS ìƒì„± í•¨ìˆ˜
# -----------------------------------------------------------------------------
def _get_zonos_config(scene: Dict[str, Any], ai: AI = None) -> Dict[str, Any]:
    """
    ì”¬ ì •ë³´ì—ì„œ Zonosìš© ì„¤ì •(emotion, speed)ì„ ê°€ì ¸ì˜¤ê±°ë‚˜,
    ê¸°ì¡´ í…ìŠ¤íŠ¸ í¬ë§·([í†¤] ë‚´ìš© [íš¨ê³¼ìŒ])ì¼ ê²½ìš° AIë¡œ ë¶„ì„í•´ ë³€í™˜(Migration)í•œë‹¤.
    """
    # 1. ì´ë¯¸ ì„¤ì •ê°’ì´ ìˆìœ¼ë©´ ë°˜í™˜
    if "voice_config" in scene:
        return scene["voice_config"]

    # 2. ì„¤ì •ê°’ì´ ì—†ìœ¼ë©´ ë‚´ë ˆì´ì…˜ íŒŒì‹± ì‹œë„
    raw_narr = scene.get("narration", "").strip()
    if not raw_narr:
        return {"speed": 1.0, "emotion": {"neutral": 1.0}}

    # ì •ê·œì‹ìœ¼ë¡œ [í†¤] ë‚´ìš© [íš¨ê³¼ìŒ] ë¶„ë¦¬
    tone_match = re.match(r"^\[(.*?)\]\s*(.*)", raw_narr)

    tone_text = "calm"
    clean_text = raw_narr
    sfx_text = ""

    if tone_match:
        tone_text = tone_match.group(1).strip()
        remain = tone_match.group(2).strip()

        # ë’¤ìª½ SFX ì²´í¬
        sfx_match = re.search(r"\s*\[(.*?)\]$", remain)
        if sfx_match:
            sfx_text = sfx_match.group(1).strip()
            clean_text = remain[:sfx_match.start()].strip()
        else:
            clean_text = remain

        # ë”°ì˜´í‘œ ì œê±°
        clean_text = clean_text.strip("'").strip('"')

    # AIì—ê²Œ ìˆ˜ì¹˜ ë³€í™˜ ìš”ì²­ (Migration)
    if ai:
        try:
            sys_p = (
                "You are a Voice Director. Analyze the 'Tone Description' and convert it into Zonos TTS parameters.\n"
                "Output JSON only: { \"speed\": float(0.8-1.5), \"emotion\": { neutral, happy, sad, disgust, fear, surprise, anger, other } (sum approx 1.0) }"
            )
            user_p = f"Tone Description: \"{tone_text}\""
            res = ai.ask_smart(sys_p, user_p, prefer="openai")

            # JSON íŒŒì‹±
            if "```" in res: res = res.split("```")[1].replace("json", "")
            config = json.loads(res[res.find("{"):res.rfind("}") + 1])

            # ì”¬ ë°ì´í„° ì—…ë°ì´íŠ¸ (ì˜êµ¬ ì €ì¥ìš©)
            scene["narration"] = clean_text
            scene["voice_config"] = config
            if sfx_text:
                scene["sfx"] = sfx_text

            return config
        except Exception as e:
            print(f"âš ï¸ í†¤ ë¶„ì„ ì‹¤íŒ¨: {e}")

    # ì‹¤íŒ¨/AI ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
    return {"speed": 1.0, "emotion": {"neutral": 1.0}}


def generate_tts_zonos(
        text: str,
        out_path: Path,
        ref_audio: Path,
        comfy_host: str = "http://127.0.0.1:8188",
        config: Dict[str, Any] = None
) -> bool:
    if not text:
        return False

    wf_path = Path(settings.JSONS_DIR) / "who_voice.json"
    if not wf_path.exists():
        wf_path = Path(r"C:\my_games\shorts_make\app\jsons\who_voice.json")

    if not wf_path.exists():
        print(f"âŒ TTS ì›Œí¬í”Œë¡œìš° ì—†ìŒ: {wf_path}")
        return False

    try:
        with open(wf_path, "r", encoding="utf-8") as f:
            graph = json.load(f)
    except Exception as e:
        print(f"âŒ ì›Œí¬í”Œë¡œìš° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

    if not ref_audio.exists():
        print(f"âŒ ì°¸ì¡° ì˜¤ë””ì˜¤ ì—†ìŒ: {ref_audio}")
        return False

    comfy_input_dir = Path(settings.COMFY_INPUT_DIR)
    comfy_input_dir.mkdir(parents=True, exist_ok=True)

    ref_copy_name = f"ref_{uuid.uuid4().hex[:8]}{ref_audio.suffix}"
    dst_ref = comfy_input_dir / ref_copy_name
    shutil.copy2(ref_audio, dst_ref)

    # 1. í…ìŠ¤íŠ¸/ì‹œë“œ/ì†ë„ ì„¤ì •
    found_gen = False
    for nid, node in graph.items():
        # Zonos ë…¸ë“œ ì°¾ê¸° (class_typeì— Zonos í¬í•¨ & inputsì— speechê°€ ìˆëŠ” ë…¸ë“œ)
        if "Zonos" in node.get("class_type", "") and "speech" in node.get("inputs", {}):
            node["inputs"]["speech"] = text
            node["inputs"]["seed"] = random.randint(1, 2 ** 32)
            if config and "speed" in config:
                node["inputs"]["speed"] = config["speed"]
            found_gen = True
            break

    # ë§Œì•½ ìœ„ ë£¨í”„ì—ì„œ ëª» ì°¾ì•˜ìœ¼ë©´ ID 24ë²ˆ ì‹œë„ (fallback)
    if not found_gen and "24" in graph:
        graph["24"]["inputs"]["speech"] = text
        graph["24"]["inputs"]["seed"] = random.randint(1, 2 ** 32)
        if config and "speed" in config:
            graph["24"]["inputs"]["speed"] = config["speed"]

    # 2. ê°ì • ì„¤ì • (Zonos Emotion ë…¸ë“œ)
    if config and "emotion" in config:
        emotions = config["emotion"]
        for nid, node in graph.items():
            if node.get("class_type") == "Zonos Emotion":
                for k, v in emotions.items():
                    if k in node["inputs"]:
                        node["inputs"][k] = v
                break

    # 3. ì°¸ì¡° ì˜¤ë””ì˜¤ ì„¤ì •
    found_audio = False
    for nid, node in graph.items():
        if node.get("class_type") == "LoadAudio":
            node["inputs"]["audio"] = ref_copy_name
            found_audio = True
            break

    if not found_audio and "12" in graph:
        graph["12"]["inputs"]["audio"] = ref_copy_name

    try:
        res = _submit_and_wait_local(comfy_host, graph, timeout=300)
        outputs = res.get("outputs", {})
        for nid, out_d in outputs.items():
            if "audio" in out_d:
                for item in out_d["audio"]:
                    fname = item["filename"]
                    params = {"filename": fname, "subfolder": item.get("subfolder", ""),
                              "type": item.get("type", "output")}
                    resp = requests.get(f"{comfy_host}/view", params=params)
                    if resp.status_code == 200:
                        ensure_dir(out_path.parent)
                        with open(out_path, "wb") as f:
                            f.write(resp.content)
                        return True
        return False
    except Exception as e:
        print(f"TTS ìƒì„± ì‹¤íŒ¨: {e}")
        return False


# -----------------------------------------------------------------------------
# 2. ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜ (2-Step: Z-Image -> Qwen)
# -----------------------------------------------------------------------------
def build_shopping_images_2step(
        video_json_path: str | Path,
        *,
        ui_width: int = 720,
        ui_height: int = 1280,
        steps: int = 28,
        on_progress: Optional[Callable[[Dict], None]] = None
) -> None:
    """
    [ìˆ˜ì •ë¨] Step 1 ë„¤ê±°í‹°ë¸Œ ì£¼ì… ì‚­ì œ (Z-Image í’ˆì§ˆ ìµœì í™”)
    """
    vpath = Path(video_json_path)
    product_dir = vpath.parent
    imgs_dir = ensure_dir(product_dir / "imgs")

    product_json_path = product_dir / "product.json"
    product_img_file = None
    if product_json_path.exists():
        try:
            pj = json.loads(product_json_path.read_text(encoding="utf-8"))
            if pj.get("image_file"):
                pi = product_dir / pj["image_file"]
                if pi.exists():
                    product_img_file = pi
        except:
            pass

    if not product_img_file:
        if on_progress: on_progress({"msg": "âŒ ì œí’ˆ ì›ë³¸ ì´ë¯¸ì§€(image.png)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ í•©ì„± ë¶ˆê°€."})

    video_doc = load_json(vpath, {})
    scenes = video_doc.get("scenes", [])
    comfy_host = getattr(settings, "COMFY_HOST", "http://127.0.0.1:8188").rstrip("/")
    comfy_input_dir = Path(settings.COMFY_INPUT_DIR)
    comfy_input_dir.mkdir(parents=True, exist_ok=True)

    # -----------------------------------------------------------
    # Step 1: Z-Image Batch (ë² ì´ìŠ¤ ìƒì„± - ë„¤ê±°í‹°ë¸Œ ì—†ì´ ì§„í–‰)
    # -----------------------------------------------------------
    if on_progress: on_progress({"msg": "=== [Step 1] ë² ì´ìŠ¤ ì´ë¯¸ì§€(Z-Image) ìƒì„± ì‹œì‘ ==="})

    wf_z_path = Path(settings.JSONS_DIR) / "Z-Image-lora.json"
    if not wf_z_path.exists():
        wf_z_path = Path(r"C:\my_games\shorts_make\app\jsons\Z-Image-lora.json")

    if wf_z_path.exists():
        with open(wf_z_path, "r", encoding="utf-8") as f:
            graph_z_origin = json.load(f)

        for sc in scenes:
            sid = sc.get("id")
            temp_file = imgs_dir / f"temp_{sid}.png"

            if temp_file.exists() and temp_file.stat().st_size > 0:
                continue

            p1 = sc.get("prompt_img_1") or sc.get("prompt_img", "")
            if not p1: continue

            if on_progress: on_progress({"msg": f"[Step 1] ë² ì´ìŠ¤ ìƒì„±: {sid}..."})

            graph = json.loads(json.dumps(graph_z_origin))
            for nid, node in graph.items():
                ctype = node.get("class_type", "")
                inputs = node.get("inputs", {})
                title = str(node.get("_meta", {}).get("title", "")).lower()

                if ctype == "CLIPTextEncode":
                    # ê¸ì • í”„ë¡¬í”„íŠ¸(Node 6)ì—ë§Œ ì…ë ¥
                    if nid == "6" or "positive" in title:
                        inputs["text"] = p1

                if "LatentImage" in ctype:
                    if "width" in inputs: inputs["width"] = ui_width
                    if "height" in inputs: inputs["height"] = ui_height

                if ctype == "KSampler" and "seed" in inputs:
                    inputs["seed"] = random.randint(1, 10 ** 9)
                    if "steps" in inputs: inputs["steps"] = steps

                if ctype == "PreviewImage":
                    node["class_type"] = "SaveImage"
                    node.setdefault("inputs", {})["filename_prefix"] = "Z_Base"

            try:
                res = _submit_and_wait_local(comfy_host, graph, on_progress=on_progress)
                outputs = res.get("outputs", {})
                found = False
                for _, out_d in outputs.items():
                    for img in out_d.get("images", []):
                        fname = img["filename"]
                        resp = requests.get(f"{comfy_host}/view", params={"filename": fname, "type": img["type"]})
                        with open(temp_file, "wb") as f:
                            f.write(resp.content)
                        found = True
                        break
                    if found: break
            except Exception as e:
                if on_progress: on_progress({"msg": f"âŒ [Step 1] ì˜¤ë¥˜({sid}): {e}"})

    # -----------------------------------------------------------
    # Step 2: Qwen Batch (ì œí’ˆ í•©ì„±)
    # -----------------------------------------------------------
    if on_progress: on_progress({"msg": "=== [Step 2] ì œí’ˆ í•©ì„±(Qwen) ì‹œì‘ ==="})

    wf_q_path = Path(settings.JSONS_DIR) / "QwenEdit2511-V1.json"
    if not wf_q_path.exists():
        wf_q_path = Path(r"C:\my_games\shorts_make\app\jsons\QwenEdit2511-V1.json")

    if not wf_q_path.exists() or not product_img_file:
        if on_progress: on_progress({"msg": "âŒ Qwen ì›Œí¬í”Œë¡œìš° ë˜ëŠ” ì œí’ˆ ì´ë¯¸ì§€ê°€ ì—†ì–´ í•©ì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤."})
        return

    with open(wf_q_path, "r", encoding="utf-8") as f:
        graph_q_origin = json.load(f)

    prod_input_name = f"prod_{uuid.uuid4().hex[:6]}.png"
    shutil.copy2(product_img_file, comfy_input_dir / prod_input_name)

    for sc in scenes:
        sid = sc.get("id")
        final_file = imgs_dir / f"{sid}.png"
        temp_file = imgs_dir / f"temp_{sid}.png"

        if final_file.exists() and final_file.stat().st_size > 0:
            sc["img_file"] = str(final_file)
            continue

        if not temp_file.exists():
            if on_progress: on_progress({"msg": f"âš ï¸ [Step 2] ë² ì´ìŠ¤ ì´ë¯¸ì§€ ì—†ìŒ(ìŠ¤í‚µ): {sid}"})
            continue

        p2 = sc.get("prompt_img_2") or ""

        if not p2:
            shutil.copy2(temp_file, final_file)
            sc["img_file"] = str(final_file)
            if on_progress: on_progress({"msg": f"â„¹ï¸ [Step 2] í•©ì„± ìƒëµ (1ë‹¨ê³„ ì‚¬ìš©): {sid}"})
            continue

        if on_progress: on_progress({"msg": f"[Step 2] í•©ì„± ì§„í–‰: {sid}..."})

        base_input_name = f"base_{sid}_{uuid.uuid4().hex[:6]}.png"
        shutil.copy2(temp_file, comfy_input_dir / base_input_name)

        graph = json.loads(json.dumps(graph_q_origin))

        if "9" in graph: graph["9"]["inputs"]["image"] = base_input_name
        if "32" in graph: graph["32"]["inputs"]["image"] = prod_input_name
        if "88" in graph: graph["88"]["inputs"]["value"] = p2

        for nid, node in graph.items():
            if node.get("class_type") == "PreviewImage":
                node["class_type"] = "SaveImage"
                node.setdefault("inputs", {})["filename_prefix"] = "ShopFinal"

        try:
            res = _submit_and_wait_local(comfy_host, graph, on_progress=on_progress)
            outputs = res.get("outputs", {})
            found = False
            for _, out_d in outputs.items():
                for img in out_d.get("images", []):
                    fname = img["filename"]
                    resp = requests.get(f"{comfy_host}/view", params={"filename": fname, "type": img["type"]})
                    with open(final_file, "wb") as f:
                        f.write(resp.content)
                    sc["img_file"] = str(final_file)
                    found = True
                    break
                if found: break
        except Exception as e:
            if on_progress: on_progress({"msg": f"âŒ [Step 2] ì˜¤ë¥˜({sid}): {e}"})

    save_json(vpath, video_doc)


# -----------------------------------------------------------------------------
# 3. ì˜µì…˜ ë°ì´í„° í´ë˜ìŠ¤
# -----------------------------------------------------------------------------
@dataclass
class BuildOptions:
    scene_count: int = 6
    style: str = "news_hook"
    hook_level: int = 3
    fps: int = 24
    allow_fallback_rule: bool = True


# -----------------------------------------------------------------------------
# 4. JSON ë¹Œë”
# -----------------------------------------------------------------------------

class ShoppingVideoJsonBuilder:
    def __init__(self, on_progress: Optional[Callable[[str], None]] = None):
        self.on_progress = on_progress or (lambda msg: None)
        self.ai = AI()

    def create_draft(self, product_dir: str | Path, product_data: Dict[str, Any], options: BuildOptions) -> Path:
        """[1ë‹¨ê³„] ê¸°íš ì´ˆì•ˆ - I2V ìµœì í™” (1ì”¬ 1ì•¡ì…˜ ê°•ì œ ë° í™”ë©´ë¶„í•  ì›ì²œ ì°¨ë‹¨)"""
        p_dir = Path(product_dir)
        vpath = p_dir / "video_shopping.json"

        product_name = product_data.get("product_name", "ìƒí’ˆëª… ì—†ìŒ")
        desc = product_data.get("description") or product_data.get("summary_source") or ""

        self.on_progress(f"[Draft] AI ê¸°íš ì‹œì‘ (ìƒí’ˆ: {product_name})...")

        system_prompt = (
            "ë‹¹ì‹ ì€ AI ì˜ìƒ ìƒì„±(I2V)ì„ ìœ„í•œ ìˆí¼ ê¸°íš ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
            "ìƒí’ˆì„ ë¶„ì„í•˜ì—¬ íŒë§¤ ìºë¦­í„°ë¥¼ ì •í•˜ê³  ê¸°íšì•ˆì„ ì‘ì„±í•˜ë˜, **AI ì˜ìƒ ìƒì„±ì— ì¹˜ëª…ì ì¸ 'í™”ë©´ ë¶„í• 'ì„ ë§‰ê¸° ìœ„í•´ ì•„ë˜ ê·œì¹™ì„ ì—„ìˆ˜**í•˜ì„¸ìš”.\n\n"
            "**[í•„ìˆ˜ ì‹œê°í™” ê·œì¹™]**\n"
            "1. **One Scene = One Action**: í•œ ì¥ë©´ì—ëŠ” ì˜¤ì§ **'í•˜ë‚˜ì˜ ë™ì‘'**ë§Œ ë¬˜ì‚¬í•˜ì„¸ìš”. (ì˜ˆ: 'ì¡ê³  ë˜ì§€ê³  ëˆë‹¤' (X) -> 'í˜ì°¨ê²Œ ë˜ì§€ëŠ” ìˆœê°„' (O))\n"
            "2. **No Split Screens**: ì»· ë¶„í• , 3ë‹¨ê³„ êµ¬ì„±, ì½œë¼ì£¼, ì¸í¬ê·¸ë˜í”½ ì ˆëŒ€ ê¸ˆì§€. ê½‰ ì°¬ ì „ì²´ í™”ë©´ìœ¼ë¡œ ê¸°íší•˜ì„¸ìš”.\n"
            "3. **Focus on Impact**: ì„¤ëª…ì ì¸ ë‚˜ì—´ë³´ë‹¤ëŠ” ì‹œê°ì ìœ¼ë¡œ ê°€ì¥ ê°•ë ¬í•œ **'ê²°ì •ì  ìˆœê°„(Keyframe)'** í•˜ë‚˜ë¥¼ í¬ì°©í•˜ì„¸ìš”."
        )

        user_prompt = f"""
        [ìƒí’ˆ ì •ë³´]
        - ìƒí’ˆëª…: {product_name}
        - ì„¤ëª…: {desc}

        [ì œì‘ ê°€ì´ë“œ]
        1. ì´ ì¥ë©´: {options.scene_count}ê°œ
        2. ìŠ¤íƒ€ì¼: {options.style}

        [ì¶œë ¥ í¬ë§· (JSON)]
        {{
            "meta": {{ 
                "title": "...", 
                "voice_gender": "female", 
                "character_prompt": "...", 
                "tone": "..." 
            }},
            "scenes": [
                {{
                    "id": "001",
                    "banner": "...",
                    "prompt": "í™”ë©´ ë¬˜ì‚¬ (í•œê¸€, ì ˆëŒ€ ì‹œí€€ìŠ¤/ë‹¨ê³„ ë‚˜ì—´ ê¸ˆì§€, ë‹¨ì¼ ë™ì‘ ìœ„ì£¼)",
                    "narration": "ì‹¤ì œ ì½ì„ ëŒ€ì‚¬ (ì§€ì‹œë¬¸ ì œì™¸)",
                    "sfx": "íš¨ê³¼ìŒ",
                    "voice_config": {{
                        "speed": 1.0, 
                        "emotion": {{ "neutral": 1.0, "happy": 0.0, "sad": 0.0, "disgust": 0.0, "fear": 0.0, "surprise": 0.0, "anger": 0.0, "other": 0.0 }}
                    }},
                    "subtitle": "..."
                }},
                ...
            ]
        }}
        """

        try:
            resp_text = self.ai.ask_smart(system_prompt, user_prompt, prefer="openai")
            data = self._safe_json_parse(resp_text)
        except Exception as e:
            self.on_progress(f"âŒ ì´ˆì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")
            raise

        final_json = {
            "schema": "shopping_shorts_v2",
            "style": options.style,
            "product": product_data,
            "meta": data.get("meta", {}),
            "defaults": {"image": {"width": 720, "height": 1280}, "movie": {"fps": options.fps}},
            "audit": {"created_at": _now_str(), "step": "draft"},
            "scenes": []
        }

        imgs_dir = p_dir / "imgs"
        clips_dir = p_dir / "clips"
        voice_dir = p_dir / "voice"

        imgs_dir.mkdir(parents=True, exist_ok=True)
        clips_dir.mkdir(parents=True, exist_ok=True)
        voice_dir.mkdir(parents=True, exist_ok=True)

        for idx, sc in enumerate(data.get("scenes", [])):
            sid = sc.get("id") or f"{idx + 1:03d}"
            new_scene = {
                "id": sid,
                "banner": sc.get("banner"),
                "prompt": sc.get("prompt", ""),
                "narration": sc.get("narration", ""),
                "sfx": sc.get("sfx", ""),
                "voice_config": sc.get("voice_config", {"speed": 1.0, "emotion": {"neutral": 1.0}}),
                "subtitle": sc.get("subtitle", ""),
                "seconds": 0,
                "prompt_img_1": "",
                "prompt_img_2": "",
                "prompt_movie": "",
                "prompt_negative": "",
                "img_file": str(imgs_dir / f"{sid}.png"),
                "movie_file": str(clips_dir / f"{sid}.mp4"),
                "voice_file": str(voice_dir / f"{sid}.wav")
            }
            final_json["scenes"].append(new_scene)

        save_json(vpath, final_json)
        self.on_progress(f"[Draft] ì´ˆì•ˆ ì™„ë£Œ. AI ì¶”ì²œ ìºë¦­í„°: {final_json['meta'].get('character_prompt')}")
        return vpath

    def enrich_video_json(self, video_json_path: str | Path, product_data: Dict[str, Any]) -> Path:
        """
        [3ë‹¨ê³„] ìƒì„¸í™” (ìµœì¢… ì™„ì„±í˜•: ìº”ë²„ìŠ¤ & ë¬¼ê° ë¶„ì—… ì „ëµ)
        - Image 1 (Canvas): ë°°ê²½/ì¸ë¬¼/ì¡°ëª…ë§Œ ë¬˜ì‚¬. ì œí’ˆì€ 'íˆ¬ëª…/ë”ë¯¸' ì²˜ë¦¬í•˜ì—¬ í™˜ê° ë°©ì§€.
        - Image 2 (Paint): 'object from image 2' í‚¤ì›Œë“œë¡œ í•©ì„± ìœ„ì¹˜ë§Œ ì§€ì •. í˜•ìš©ì‚¬ ê¸ˆì§€.
        - Audio: ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜ ë° ì¸¡ì •.
        - [ê°•í™”] ëª¨ë“  í”„ë¡¬í”„íŠ¸ ì¶œë ¥ì€ ë°˜ë“œì‹œ 'ì˜ì–´'ë¡œ ì‘ì„±í•˜ë„ë¡ ê°•ì œ.
        """
        vpath = Path(video_json_path)
        p_dir = vpath.parent
        voice_dir = ensure_dir(p_dir / "voice")

        data = load_json(vpath, {})
        scenes = data.get("scenes", [])

        # ---------------------------------------------------------------------
        # 1. ì˜¤ë””ì˜¤ ìƒì„± ë° ì¸¡ì • (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        # ---------------------------------------------------------------------
        gender = data.get("meta", {}).get("voice_gender", "female").lower()
        if "male" == gender:
            ref_voice = Path(r"C:\my_games\shorts_make\voice\ë‚¨ìì„±ìš°1.mp3")
        else:
            ref_voice = Path(r"C:\my_games\shorts_make\voice\ê¼¬ê¼¬ ìŒì„±.m4a")

        self.on_progress(f"[Enrich] 1/2ë‹¨ê³„: ìŒì„± ìƒì„± ({gender}) ë° ì •ë°€ ì¸¡ì •...")
        comfy_host = getattr(settings, "COMFY_HOST", "http://127.0.0.1:8188")
        total_dur = 0.0

        for sc in scenes:
            sid = sc["id"]

            # í…ìŠ¤íŠ¸ íŒŒì‹± ë° ìˆ˜ì¹˜ ë³€í™˜
            config = _get_zonos_config(sc, self.ai)
            narr = sc.get("narration", "").strip()
            v_path = Path(sc.get("voice_file") or str(voice_dir / f"{sid}.wav"))

            if not narr:
                if sc.get("seconds", 0) == 0: sc["seconds"] = 3
                total_dur += sc["seconds"]
                continue

            # ìŒì„± ìƒì„±
            if not v_path.exists() or v_path.stat().st_size == 0:
                self.on_progress(f"   ğŸ™ï¸ Scene {sid} ìŒì„± ìƒì„± (ì†ë„: {config.get('speed', 1.0)})...")
                success = generate_tts_zonos(narr, v_path, ref_voice, comfy_host, config)
                if not success:
                    sc["seconds"] = 4
                    total_dur += 4
                    self.on_progress(f"      âŒ ìƒì„± ì‹¤íŒ¨ (ê¸°ë³¸ 4ì´ˆ)")
                    continue

            # ì‹œê°„ ì¸¡ì •
            final_dur = 0.0
            max_retries = 5
            for i in range(max_retries):
                if v_path.exists() and v_path.stat().st_size > 0:
                    try:
                        dur = get_audio_duration(str(v_path))
                        if dur > 0:
                            final_dur = dur
                            self.on_progress(f"      âœ… ì¸¡ì • ì™„ë£Œ: {dur:.2f}ì´ˆ")
                            break
                    except Exception:
                        pass
                if i < max_retries - 1:
                    time.sleep(0.5)

            if final_dur > 0:
                sc["seconds"] = round(final_dur + 0.5, 2)
            else:
                sc["seconds"] = 4
                self.on_progress(f"      âŒ ì¸¡ì • ì‹¤íŒ¨ (ê¸°ë³¸ 4ì´ˆ)")

            sc["voice_file"] = str(v_path)
            total_dur += sc["seconds"]

        data.setdefault("meta", {})["total_duration"] = round(total_dur, 2)
        save_json(vpath, data)

        # ---------------------------------------------------------------------
        # 2. [í•µì‹¬] í”„ë¡¬í”„íŠ¸ ìƒì„¸í™” (Canvas & Paint ì „ëµ) - ì˜ì–´ ê°•ì œ ê°•í™”
        # ---------------------------------------------------------------------
        self.on_progress("[Enrich] 2/2ë‹¨ê³„: ë¹„ì£¼ì–¼ í”„ë¡¬í”„íŠ¸ ê³ ë„í™” (í•©ì„± ìµœì í™” + ì˜ì–´ ë³€í™˜)...")

        char_prompt = data.get("meta", {}).get("character_prompt", "Young Korean model")
        if "male" == gender:
            gender_kw = "male, man, 1boy"
        else:
            gender_kw = "female, woman, 1girl"

        scene_texts = []
        for sc in scenes:
            sfx_info = f" (SFX: {sc.get('sfx')})" if sc.get("sfx") else ""
            scene_texts.append(f"- Scene {sc['id']} (ì§€ë¬¸): {sc.get('prompt')}{sfx_info}")

        # [ìˆ˜ì •] ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— 'ì˜ì–´ ì‘ì„±' ê·œì¹™ì„ ë§¤ìš° ê°•ë ¥í•˜ê²Œ ëª…ì‹œ
        sys_p = (
            "You are a ComfyUI Compositing Director. "
            "Your task is to generate 2-step image generation prompts based on the provided scenario.\n"
            "The image generation process consists of two steps: 1. Background/Character (Canvas) -> 2. Product Inpainting (Paint).\n\n"
            "**[CRITICAL RULE]**\n"
            "1. **LANGUAGE: ALL OUTPUT PROMPTS MUST BE IN ENGLISH.** Translate any Korean input into detailed English descriptions.\n"
            "2. **NO KOREAN CHARACTERS** in the `prompt_img_1`, `prompt_img_2`, `prompt_movie`, or `prompt_negative` fields.\n"
        )

        user_p = f"""
        [Prompting Strategy: Canvas & Paint]

        **Context Info**:
        - Character Style: "{char_prompt}"
        - Gender Keywords: "{gender_kw}"

        Analyze each scene to determine if it's a **[Person Shot]** or **[Product-only Shot]**, then apply the rules below.

        ---
        ### 1. `prompt_img_1` (The Canvas: Base Image)
        *Goal: Prepare the perfect background and pose, leaving a space for the product.*
        * **FORBIDDEN**: Do NOT describe the product itself (No colors, No logos, No specific materials of the product).

        **(A) Person Shot**
        - Focus on the **Gesture** and **Expression**.
        - Hand: Describe the hand as **"holding a generic invisible cylinder"** or **"empty hand with open palm"** to reserve space for the product.
        - Example: "A {gender_kw} extending arm, hand gripping a generic invisible cylinder, focused expression, soft lighting."

        **(B) Product-only Shot**
        - Focus on **Background Surface** and **Lighting**.
        - Leave the center empty: "Empty space in center ready for product placement."
        - Example: "Elegant wooden table surface, sunlight from window, bokeh background, empty center area."

        ### 2. `prompt_img_2` (The Paint: Inpainting)
        *Goal: Composite the actual product onto the canvas.*
        * **MANDATORY**: You MUST use the exact phrase **"object from image 2"** to refer to the product.
        * **FORBIDDEN**: Do NOT use adjectives for the product (e.g., "red bottle", "round shape"). The AI knows the product image.
        * **NO NEGATIVES**: Do not use "no color", "ignore material".

        - Format 1 (Person): "The [Subject] holding the **object from image 2** in hand."
        - Format 2 (Background): "The **object from image 2** placed on the surface."
        - Format 3 (Action): "The **object from image 2** flying in the air."

        ### 3. `prompt_negative`
        - Standard: "text, watermark, username, signature, title, low quality, deformed hands, missing fingers, extra limbs".
        - Anti-Hallucination: "product details, specific logo, complex object, holding random object" (Prevents random items in base image).

        ### 4. `prompt_movie`
        - Camera movement description in English (e.g., "Slow zoom in", "Tracking shot").

        [Input Scenarios (Korean)]
        {chr(10).join(scene_texts)}

        [Output Format (JSON Only)]
        {{
            "scenes": {{
                "scene_id_1": {{
                    "prompt_img_1": "English description...",
                    "prompt_img_2": "English description...",
                    "prompt_negative": "English description...",
                    "prompt_movie": "English description..."
                }},
                ...
            }}
        }}
        """

        try:
            resp = self.ai.ask_smart(sys_p, user_p, prefer="openai")
            enriched = self._safe_json_parse(resp)

            # íŒŒì‹±ëœ ê²°ê³¼ ë³‘í•©
            en_map = enriched.get("scenes", {})
            # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì¼ ê²½ìš° ëŒ€ë¹„ (ê°€ë” AIê°€ ë¦¬ìŠ¤íŠ¸ë¡œ ì¤„ ë•Œê°€ ìˆìŒ)
            if isinstance(en_map, list):
                en_map = {item.get("id", f"t_{i + 1:03d}"): item for i, item in enumerate(en_map)}

            for sc in scenes:
                sid = sc["id"]
                # ID ë§¤ì¹­ ì‹œë„ (t_001 <-> 001 í˜¸í™˜)
                tgt = en_map.get(sid) or en_map.get(sid.replace("t_", "")) or en_map.get(sid.split("_")[-1])

                if tgt:
                    sc["prompt_img_1"] = tgt.get("prompt_img_1", "")
                    sc["prompt_img_2"] = tgt.get("prompt_img_2", "")
                    sc["prompt_negative"] = tgt.get("prompt_negative", "")
                    sc["prompt_movie"] = tgt.get("prompt_movie", "")
                    # í˜¸í™˜ì„±ì„ ìœ„í•´ prompt_imgì—ë„ 1ë²ˆ í”„ë¡¬í”„íŠ¸ ë³µì‚¬
                    sc["prompt_img"] = sc["prompt_img_1"]

            data["audit"]["enriched_at"] = _now_str()
            data["audit"]["step"] = "enriched"

            save_json(vpath, data)
            self.on_progress(f"[Enrich] ìƒì„¸í™” ì™„ë£Œ (ì´ {total_dur:.1f}ì´ˆ, ì˜ì–´ ë³€í™˜ ì ìš©ë¨).")

        except Exception as e:
            self.on_progress(f"âŒ ìƒì„¸í™” AI ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ë¥¼ ë˜ì ¸ì„œ ìƒìœ„ì—ì„œ ì•Œ ìˆ˜ ìˆê²Œ í•¨ (ì„ íƒ)
            # raise e

        return vpath

    def _safe_json_parse(self, text: str) -> Dict:
        try:
            text = re.sub(r"```json", "", text, flags=re.I).replace("```", "")
            return json.loads(text)
        except:
            s, e = text.find("{"), text.rfind("}")
            if s != -1 and e != -1:
                return json.loads(text[s:e + 1])
            raise ValueError("Invalid JSON response")


# -----------------------------------------------------------------------------
# 5. ì´ë¯¸ì§€ ìƒì„±ê¸°
# -----------------------------------------------------------------------------
class ShoppingImageGenerator:
    def __init__(self, on_progress: Optional[Callable[[str], None]] = None):
        self.on_progress = on_progress or (lambda msg: None)

    def generate_images(self, video_json_path: str | Path, skip_if_exists: bool = True) -> None:
        def _cb(d):
            self.on_progress(d.get("msg", ""))

        # 1. í•´ìƒë„ ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’ ì•ˆì „ì¥ì¹˜ í¬í•¨)
        img_size = settings.DEFAULT_IMG_SIZE
        width_val = img_size[0]  # ê°€ë¡œ
        height_val = img_size[1]  # ì„¸ë¡œ

        # 2. ìŠ¤í… ìˆ˜ ê°€ì ¸ì˜¤ê¸°
        steps_val = settings.DEFAULT_T2I_STEPS

        try:
            build_shopping_images_2step(
                video_json_path=video_json_path,
                ui_width=width_val,  # settingsì—ì„œ ê°€ì ¸ì˜¨ ê°€ë¡œê°’
                ui_height=height_val,  # settingsì—ì„œ ê°€ì ¸ì˜¨ ì„¸ë¡œê°’
                steps=steps_val,  # settingsì—ì„œ ê°€ì ¸ì˜¨ ìŠ¤í… ìˆ˜
                on_progress=_cb
            )
        except Exception as e:
            self.on_progress(f"âŒ ì´ë¯¸ì§€ ìƒì„± ì˜¤ë¥˜: {e}")
            raise e

# -----------------------------------------------------------------------------
# 6. ì˜ìƒ ìƒì„±/ë³‘í•©ê¸°
# -----------------------------------------------------------------------------
class ShoppingMovieGenerator:
    def __init__(self, on_progress: Optional[Callable[[str], None]] = None):
        self.on_progress = on_progress or (lambda msg: None)

    def generate_movies(self, video_json_path: str | Path, skip_if_exists: bool = True, fps: int = 24) -> None:
        vpath = Path(video_json_path)  # ì´ê²ƒì€ video_shopping.json ì…ë‹ˆë‹¤.
        project_dir = vpath.parent

        # [ì¤‘ìš”] I2V ì—”ì§„(build_shots_with_i2v)ì€ ë¬´ì¡°ê±´ 'video.json'ì„ ì°¾ìŠµë‹ˆë‹¤.
        # ë”°ë¼ì„œ video_shopping.json ë‚´ìš©ì„ ë³µì‚¬í•œ 'ì„ì‹œ íŒŒì¼'ì„ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.
        temp_video_json = project_dir / "video.json"

        self.on_progress(f"[Movie] I2V ì¤€ë¹„: {vpath.name}")

        # 1. video_shopping.json ë‚´ìš©ì„ ì½ìŒ
        data = load_json(vpath, {})

        # 2. duration ì•ˆì „ì¥ì¹˜ (0ì´ë©´ ê¸°ë³¸ê°’ ë¶€ì—¬)
        for sc in data.get("scenes", []):
            if float(sc.get("duration", 0)) <= 0:
                sc["duration"] = float(sc.get("seconds", 4.0))

        # 3. ì„ì‹œ íŒŒì¼(video.json)ë¡œ ì €ì¥ -> ì—”ì§„ì´ ì´ê±¸ ì½ìŒ
        save_json(temp_video_json, data)

        def _cb(d):
            self.on_progress(d.get("msg", ""))

        try:
            # 4. ì—”ì§„ ì‹¤í–‰ (ì—”ì§„ì€ í´ë” ë‚´ì˜ video.jsonì„ ìë™ìœ¼ë¡œ ì°¾ìŒ)
            build_shots_with_i2v(str(project_dir), total_frames=0, ui_fps=fps, on_progress=_cb)
            self.on_progress("[Movie] ìƒì„± ì™„ë£Œ")
        finally:
            # 5. [í•„ìˆ˜] ì‘ì—…ì´ ëë‚˜ë©´ ì„ì‹œ íŒŒì¼(video.json)ì€ í—·ê°ˆë¦¬ì§€ ì•Šê²Œ ì‚­ì œ
            if temp_video_json.exists():
                try:
                    os.remove(temp_video_json)
                    # self.on_progress("â„¹ï¸ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
                except:
                    pass

    def merge_movies(self, video_json_path: str | Path):
        vpath = Path(video_json_path)
        project_dir = vpath.parent
        clips_dir = project_dir / "clips"

        self.on_progress("[Merge] ì˜ìƒ í•©ì¹˜ê¸°...")
        data = load_json(vpath, {})
        clip_paths = []
        for sc in data.get("scenes", []):
            cpath = clips_dir / f"{sc['id']}.mp4"
            if cpath.exists():
                clip_paths.append(cpath)

        if not clip_paths:
            self.on_progress("âŒ ë³‘í•©í•  í´ë¦½ ì—†ìŒ")
            return

        out_path = project_dir / "final_shopping_video.mp4"
        ffmpeg_exe = getattr(settings, "FFMPEG_EXE", "ffmpeg")
        concatenate_scene_clips(clip_paths, out_path, ffmpeg_exe)
        self.on_progress(f"âœ… ë³‘í•© ì™„ë£Œ: {out_path.name}")


# -----------------------------------------------------------------------------
# 7. íŒŒì´í”„ë¼ì¸
# -----------------------------------------------------------------------------
class ShoppingShortsPipeline:
    def __init__(self, on_progress: Optional[Callable[[str], None]] = None):
        self.on_progress = on_progress or (lambda msg: None)

    def run_all(
            self,
            product_dir: str | Path,
            product_data: Dict[str, Any],
            options: Optional[BuildOptions] = None,
            build_json: bool = True,
            build_images: bool = True,
            build_movies: bool = True,
            merge: bool = True,
            skip_if_exists: bool = True,
    ) -> Path:
        options = options or BuildOptions()
        vpath = Path(product_dir) / "video_shopping.json"

        builder = ShoppingVideoJsonBuilder(self.on_progress)

        if build_json:
            if not vpath.exists():
                vpath = builder.create_draft(product_dir, product_data, options)
            builder.enrich_video_json(vpath, product_data)

        if build_images:
            img_gen = ShoppingImageGenerator(self.on_progress)
            img_gen.generate_images(vpath, skip_if_exists)

        if build_movies:
            mov_gen = ShoppingMovieGenerator(self.on_progress)
            mov_gen.generate_movies(vpath, skip_if_exists, fps=options.fps)

        if merge:
            mov_gen = ShoppingMovieGenerator(self.on_progress)
            mov_gen.merge_movies(vpath)

        return vpath



def convert_shopping_to_video_json_with_ai(
        project_dir: str,
        ai_client: Any = None,
        fps: int = 30,
        width: int = 1080,
        height: int = 1920,
        steps: int = 20,  # [New] UIì—ì„œ ì „ë‹¬ë°›ì„ Steps ì¸ì ì¶”ê°€
        on_progress: Optional[Callable[[Dict[str, Any]], None]] = None
) -> str:
    """
    [ì‡¼í•‘->ì‡¼ì¸  ë³€í™˜]
    video_shopping.jsonì„ ì½ì–´ì„œ Shorts íƒ­ê³¼ í˜¸í™˜ë˜ëŠ” video.jsonì„ ìƒì„±í•©ë‹ˆë‹¤.
    UIì—ì„œ ì…ë ¥ë°›ì€ FPS, í•´ìƒë„, Steps ê°’ì„ video.jsonì— ì˜êµ¬ ì €ì¥í•©ë‹ˆë‹¤.
    """

    def _log(msg: str):
        if on_progress:
            on_progress({"msg": msg})
        print(f"[ShoppingConverter] {msg}")

    proj_path = Path(project_dir)
    src_json_path = proj_path / "video_shopping.json"
    dst_json_path = proj_path / "video.json"

    if not src_json_path.exists():
        raise FileNotFoundError(f"video_shopping.jsonì´ ì—†ìŠµë‹ˆë‹¤: {src_json_path}")

    # 1. ì‡¼í•‘ ë°ì´í„° ë¡œë“œ
    try:
        with open(src_json_path, "r", encoding="utf-8") as f:
            src_data = json.load(f)
    except Exception as e:
        raise ValueError(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")

    _log("ë°ì´í„° êµ¬ì¡° ë³€í™˜ ì‹œì‘...")

    # 2. ê¸°ë³¸ ì •ë³´ ë§¤í•‘
    prod = src_data.get("product", {})
    project_name = prod.get("product_name") or src_data.get("project_name", "Shopping Project")
    src_scenes = src_data.get("scenes", [])
    if not src_scenes:
        src_scenes = src_data.get("groups", [])

    # 3. video.json ì”¬ ë¦¬ìŠ¤íŠ¸ ì¡°ë¦½
    new_scenes = []
    current_time = 0.0
    full_lyrics_parts = []

    for idx, sc in enumerate(src_scenes):
        scene_id = f"t_{idx + 1:03d}"
        dur = float(sc.get("seconds") or sc.get("duration") or 4.0)
        start_t = current_time
        end_t = current_time + dur
        current_time = end_t

        narration = str(sc.get("narration") or sc.get("narration_text") or "")
        full_lyrics_parts.append(narration)

        new_scene = {
            "id": scene_id,
            "section": "main",
            "start": round(start_t, 3),
            "end": round(end_t, 3),
            "duration": round(dur, 3),
            "img_file": sc.get("img_file") or sc.get("image_path") or "",
            "voice_file": sc.get("voice_file") or sc.get("audio_path") or "",
            "lyric": narration,
            "prompt": sc.get("prompt", ""),
            "prompt_movie": sc.get("prompt_movie", ""),
            "prompt_img": sc.get("prompt_img", ""),
            "prompt_negative": sc.get("prompt_negative", ""),
            "effect": [],
            "screen_transition": (idx == len(src_scenes) - 1)
        }
        new_scenes.append(new_scene)

    total_duration = current_time
    full_lyrics = "\n".join(full_lyrics_parts)

    # 4. video.json ë¼ˆëŒ€ ì €ì¥ (UI ì„¤ì •ê°’ ë°˜ì˜)
    video_data = {
        "title": project_name,
        "duration": round(total_duration, 3),
        "fps": fps,  # [UIê°’] ìµœìƒìœ„ FPS ì €ì¥
        "lyrics": full_lyrics,
        "scenes": new_scenes,
        "defaults": {
            "movie": {
                "fps": fps,
                "target_fps": fps,
                "input_fps": fps
            },
            "image": {
                "width": width,   # [UIê°’] í•´ìƒë„ ì €ì¥
                "height": height, # [UIê°’] í•´ìƒë„ ì €ì¥
                "fps": fps
            },
            # [New] ìƒì„± ê´€ë ¨ íŒŒë¼ë¯¸í„° ì €ì¥ (ë‚˜ì¤‘ì— UIê°€ ì´ ê°’ì„ ì½ì–´ì˜´)
            "generator": {
                "steps": steps
            }
        },
        "audit": {
            "source": "shopping_converter_v2",
            "converted_at": str(datetime.datetime.now())
        }
    }

    with open(dst_json_path, "w", encoding="utf-8") as f:
        json.dump(video_data, f, indent=2, ensure_ascii=False)

    _log(f"video.json ì €ì¥ ì™„ë£Œ (FPS: {fps}, Size: {width}x{height}, Steps: {steps})")
    _log("AI ìƒì„¸í™” ì§„í–‰...")

    # 5. [í•µì‹¬] app.video_build í•¨ìˆ˜ ì¬ì‚¬ìš© -> ì„¸ê·¸ë¨¼íŠ¸ë³„ í”„ë¡¬í”„íŠ¸(frame_segments) ìƒì„±
    if ai_client:
        try:
            # [Fix] AI ê°ì²´ë¥¼ í•¨ìˆ˜ ë˜í¼ë¡œ ë³€í™˜í•˜ì—¬ ì „ë‹¬ (TypeError ë°©ì§€)
            def ask_wrapper(sys_msg, user_msg):
                return ai_client.ask_smart(sys_msg, user_msg, prefer="openai")

            # fill_prompt_movie_with_aiëŠ” video.json ê²½ë¡œë¥¼ ë°›ì•„ ë¡œë“œ í›„,
            # ê°­(Gap) ì •ì±…, ì„¸ê·¸ë¨¼íŠ¸ ë¶„í• , AI í”„ë¡¬í”„íŠ¸ ì±„ìš°ê¸°ë¥¼ ìˆ˜í–‰í•˜ê³  ë‹¤ì‹œ ì €ì¥í•¨.
            fill_prompt_movie_with_ai(
                str(dst_json_path.parent),  # [Fix] íŒŒì¼ì´ ì•„ë‹Œ 'í´ë”' ê²½ë¡œ ì „ë‹¬
                ask_wrapper,                # [Fix] ë˜í¼ í•¨ìˆ˜ ì „ë‹¬
                log_fn=_log                 # [Fix] ë¡œê·¸ í•¨ìˆ˜ ì „ë‹¬
            )
            _log("âœ… AI ìƒì„¸í™”(Segments/Prompts) ì™„ë£Œ.")
        except Exception as e:
            _log(f"âŒ AI ìƒì„¸í™” ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨í•´ë„ ê¸°ë³¸ video.jsonì€ ìˆìœ¼ë¯€ë¡œ ì¤‘ë‹¨í•˜ì§€ ì•ŠìŒ (í•„ìš”ì‹œ raise)

    return str(dst_json_path)

#