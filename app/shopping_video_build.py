# -*- coding: utf-8 -*-
from __future__ import annotations

import datetime
import json
import re
import shutil
import os
import random
import requests
import time
import uuid
import math
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional

# [ìˆ˜ì •] ê°•ë ¥í•œ ì˜¤ë””ì˜¤ ì¸¡ì • í•¨ìˆ˜(audio_duration_sec) ì‚¬ìš©
from app.utils import (
    AI,
    load_json,
    save_json,
    ensure_dir
)
from app import settings
from app.video_build import build_shots_with_i2v, concatenate_scene_clips, fill_prompt_movie_with_ai
from app.audio_sync import get_audio_duration

def _now_str() -> str:
    return datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")


# -----------------------------------------------------------------------------
# [New] ComfyUI ì œì¶œ ë° ëŒ€ê¸° í•¨ìˆ˜ (ë…ë¦½í˜•)
# -----------------------------------------------------------------------------
def _submit_and_wait_local(
        base_url: str,
        graph: dict,
        timeout: int = 900,
        poll: float = 2.0,
        on_progress: Optional[Callable[[Dict[str, Any]], None]] = None
) -> dict:
    """ComfyUI ì›Œí¬í”Œë¡œìš° ì œì¶œ ë° ëŒ€ê¸°"""
    client_id = str(uuid.uuid4())
    payload = {"prompt": graph, "client_id": client_id}

    try:
        resp = requests.post(f"{base_url}/prompt", json=payload, timeout=30)
        resp.raise_for_status()
        prompt_id = resp.json().get("prompt_id")
    except Exception as e:
        raise RuntimeError(f"ComfyUI ì œì¶œ ì‹¤íŒ¨: {e}")

    start_t = time.time()
    while True:
        elapsed = time.time() - start_t
        if elapsed > timeout:
            raise TimeoutError(f"ComfyUI ì‹œê°„ ì´ˆê³¼ ({elapsed:.1f}s)")

        try:
            h_resp = requests.get(f"{base_url}/history/{prompt_id}", timeout=10)
            if h_resp.status_code == 200:
                h_data = h_resp.json()
                if prompt_id in h_data:
                    return h_data[prompt_id]
        except Exception:
            pass
        time.sleep(poll)


# -----------------------------------------------------------------------------
# 1. Zonos TTS ìƒì„± í•¨ìˆ˜
# -----------------------------------------------------------------------------
def _get_zonos_config(scene: Dict[str, Any], ai: AI = None) -> Dict[str, Any]:
    """
    ì”¬ ì •ë³´ì—ì„œ Zonosìš© ì„¤ì •(emotion, speed)ì„ ê°€ì ¸ì˜¤ê±°ë‚˜,
    ê¸°ì¡´ í…ìŠ¤íŠ¸ í¬ë§·([í†¤] ë‚´ìš© [íš¨ê³¼ìŒ])ì¼ ê²½ìš° AIë¡œ ë¶„ì„í•´ ë³€í™˜(Migration)í•œë‹¤.
    """
    # 1. ì´ë¯¸ ì„¤ì •ê°’ì´ ìˆìœ¼ë©´ ë°˜í™˜
    if "voice_config" in scene:
        return scene["voice_config"]

    # 2. ì„¤ì •ê°’ì´ ì—†ìœ¼ë©´ ë‚´ë ˆì´ì…˜ íŒŒì‹± ì‹œë„
    raw_narr = scene.get("narration", "").strip()
    if not raw_narr:
        return {"speed": 1.0, "emotion": {"neutral": 1.0}}

    # ì •ê·œì‹ìœ¼ë¡œ [í†¤] ë‚´ìš© [íš¨ê³¼ìŒ] ë¶„ë¦¬
    tone_match = re.match(r"^\[(.*?)\]\s*(.*)", raw_narr)

    tone_text = "calm"
    clean_text = raw_narr
    sfx_text = ""

    if tone_match:
        tone_text = tone_match.group(1).strip()
        remain = tone_match.group(2).strip()

        # ë’¤ìª½ SFX ì²´í¬
        sfx_match = re.search(r"\s*\[(.*?)\]$", remain)
        if sfx_match:
            sfx_text = sfx_match.group(1).strip()
            clean_text = remain[:sfx_match.start()].strip()
        else:
            clean_text = remain

        # ë”°ì˜´í‘œ ì œê±°
        clean_text = clean_text.strip("'").strip('"')

    # AIì—ê²Œ ìˆ˜ì¹˜ ë³€í™˜ ìš”ì²­ (Migration)
    if ai:
        try:
            sys_p = (
                "You are a Voice Director. Analyze the 'Tone Description' and convert it into Zonos TTS parameters.\n"
                "Output JSON only: { \"speed\": float(0.8-1.5), \"emotion\": { neutral, happy, sad, disgust, fear, surprise, anger, other } (sum approx 1.0) }"
            )
            user_p = f"Tone Description: \"{tone_text}\""
            res = ai.ask_smart(sys_p, user_p, prefer="openai")

            # JSON íŒŒì‹±
            if "```" in res: res = res.split("```")[1].replace("json", "")
            config = json.loads(res[res.find("{"):res.rfind("}") + 1])

            # ì”¬ ë°ì´í„° ì—…ë°ì´íŠ¸ (ì˜êµ¬ ì €ì¥ìš©)
            scene["narration"] = clean_text
            scene["voice_config"] = config
            if sfx_text:
                scene["sfx"] = sfx_text

            return config
        except Exception as e:
            print(f"âš ï¸ í†¤ ë¶„ì„ ì‹¤íŒ¨: {e}")

    # ì‹¤íŒ¨/AI ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
    return {"speed": 1.0, "emotion": {"neutral": 1.0}}


def generate_tts_zonos(
        text: str,
        out_path: Path,
        ref_audio: Path,
        comfy_host: str = "http://127.0.0.1:8188",
        config: Dict[str, Any] = None
) -> bool:
    if not text:
        return False

    wf_path = Path(settings.JSONS_DIR) / "who_voice.json"
    if not wf_path.exists():
        wf_path = Path(r"C:\my_games\shorts_make\app\jsons\who_voice.json")

    if not wf_path.exists():
        print(f"âŒ TTS ì›Œí¬í”Œë¡œìš° ì—†ìŒ: {wf_path}")
        return False

    try:
        with open(wf_path, "r", encoding="utf-8") as f:
            graph = json.load(f)
    except Exception as e:
        print(f"âŒ ì›Œí¬í”Œë¡œìš° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

    if not ref_audio.exists():
        print(f"âŒ ì°¸ì¡° ì˜¤ë””ì˜¤ ì—†ìŒ: {ref_audio}")
        return False

    comfy_input_dir = Path(settings.COMFY_INPUT_DIR)
    comfy_input_dir.mkdir(parents=True, exist_ok=True)

    ref_copy_name = f"ref_{uuid.uuid4().hex[:8]}{ref_audio.suffix}"
    dst_ref = comfy_input_dir / ref_copy_name
    shutil.copy2(ref_audio, dst_ref)

    # 1. í…ìŠ¤íŠ¸/ì‹œë“œ/ì†ë„ ì„¤ì •
    found_gen = False
    for nid, node in graph.items():
        # Zonos ë…¸ë“œ ì°¾ê¸° (class_typeì— Zonos í¬í•¨ & inputsì— speechê°€ ìˆëŠ” ë…¸ë“œ)
        if "Zonos" in node.get("class_type", "") and "speech" in node.get("inputs", {}):
            node["inputs"]["speech"] = text
            node["inputs"]["seed"] = random.randint(1, 2 ** 32)
            if config and "speed" in config:
                node["inputs"]["speed"] = config["speed"]
            found_gen = True
            break

    # ë§Œì•½ ìœ„ ë£¨í”„ì—ì„œ ëª» ì°¾ì•˜ìœ¼ë©´ ID 24ë²ˆ ì‹œë„ (fallback)
    if not found_gen and "24" in graph:
        graph["24"]["inputs"]["speech"] = text
        graph["24"]["inputs"]["seed"] = random.randint(1, 2 ** 32)
        if config and "speed" in config:
            graph["24"]["inputs"]["speed"] = config["speed"]

    # 2. ê°ì • ì„¤ì • (Zonos Emotion ë…¸ë“œ)
    if config and "emotion" in config:
        emotions = config["emotion"]
        for nid, node in graph.items():
            if node.get("class_type") == "Zonos Emotion":
                for k, v in emotions.items():
                    if k in node["inputs"]:
                        node["inputs"][k] = v
                break

    # 3. ì°¸ì¡° ì˜¤ë””ì˜¤ ì„¤ì •
    found_audio = False
    for nid, node in graph.items():
        if node.get("class_type") == "LoadAudio":
            node["inputs"]["audio"] = ref_copy_name
            found_audio = True
            break

    if not found_audio and "12" in graph:
        graph["12"]["inputs"]["audio"] = ref_copy_name

    try:
        res = _submit_and_wait_local(comfy_host, graph, timeout=300)
        outputs = res.get("outputs", {})
        for nid, out_d in outputs.items():
            if "audio" in out_d:
                for item in out_d["audio"]:
                    fname = item["filename"]
                    params = {"filename": fname, "subfolder": item.get("subfolder", ""),
                              "type": item.get("type", "output")}
                    resp = requests.get(f"{comfy_host}/view", params=params)
                    if resp.status_code == 200:
                        ensure_dir(out_path.parent)
                        with open(out_path, "wb") as f:
                            f.write(resp.content)
                        return True
        return False
    except Exception as e:
        print(f"TTS ìƒì„± ì‹¤íŒ¨: {e}")
        return False



# -----------------------------------------------------------------------------
# 1.5 BGM ìƒì„± í•¨ìˆ˜ (Ace-Step) - [New]
# -----------------------------------------------------------------------------
def generate_bgm_acestep(
        prompt: str,
        out_path: Path,
        duration_sec: float,
        comfy_host: str = "http://127.0.0.1:8188",
        negative_prompt: str = "vocal, vocals, singing, human voice, lyrics, rap, speech, chant, noise, distortion"
) -> bool:
    """
    [ì‡¼í•‘ ì „ìš©] Ace-Step ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°°ê²½ìŒ(BGM) ìƒì„±
    - ê°€ì‚¬ ìƒì„± ë°©ì§€(lyrics_strength=0) ë° Instrumental ê°•ì œ
    """
    if not prompt:
        return False

    # ì›Œí¬í”Œë¡œìš° ë¡œë“œ
    wf_path = Path(settings.JSONS_DIR) / "ace_step_1_t2mm.json"
    if not wf_path.exists():
        # ê¸°ë³¸ ê²½ë¡œ í´ë°±
        wf_path = Path(r"C:\my_games\shorts_make\app\jsons\ace_step_1_t2mm.json")

    if not wf_path.exists():
        print(f"âŒ Ace-Step ì›Œí¬í”Œë¡œìš° ì—†ìŒ: {wf_path}")
        return False

    try:
        with open(wf_path, "r", encoding="utf-8") as f:
            graph = json.load(f)
    except Exception as e:
        print(f"âŒ ì›Œí¬í”Œë¡œìš° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

    # ë…¸ë“œ ë§¤í•‘ ë° ê°’ ì£¼ì…
    # 14: TextEncodeAceStepAudio (tags, lyrics_strength)
    # 80: CLIPTextEncode (Negative)
    # 17: EmptyAceStepLatentAudio (seconds)
    # 52: KSampler (seed)
    # 78: SaveAudioMP3 (filename)

    # 1. ê¸ì • í”„ë¡¬í”„íŠ¸ & ê°€ì‚¬ ì–µì œ
    if "14" in graph:
        graph["14"]["inputs"]["tags"] = prompt
        graph["14"]["inputs"]["lyrics_strength"] = 0  # ê°€ì‚¬ ë°©ì§€ í•µì‹¬
        # lyrics ì…ë ¥ ëŠê¸° (ì•ˆì „ì¥ì¹˜) -> ë¹ˆ ë¬¸ìì—´ì„ ì£¼ëŠ” ë…¸ë“œê°€ ìˆë‹¤ë©´ ì—°ê²°, ì•„ë‹ˆë©´ í…ìŠ¤íŠ¸ ë¹„ìš°ê¸°
        # ì—¬ê¸°ì„œëŠ” tagsì—ë§Œ ì˜ì¡´í•˜ê³  lyrics_strength=0ìœ¼ë¡œ ì œì–´

    # 2. ë¶€ì • í”„ë¡¬í”„íŠ¸ (ë³´ì»¬ ë°©ì§€)
    if "80" in graph:
        graph["80"]["inputs"]["text"] = negative_prompt

    # 3. ê¸¸ì´ ì„¤ì • (ì—¬ìœ ë¶„ 3ì´ˆ ì¶”ê°€)
    target_sec = math.ceil(duration_sec + 3.0)
    if "17" in graph:
        graph["17"]["inputs"]["seconds"] = target_sec

    # 4. ì‹œë“œ ëœë¤í™”
    if "52" in graph:
        graph["52"]["inputs"]["seed"] = random.randint(1, 2 ** 32)

    # 5. ì €ì¥ ê²½ë¡œ ì„¤ì •
    # ComfyUI output í´ë” ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ
    # ì˜ˆ: "bgm/product_name_bgm" (í™•ì¥ìëŠ” SaveAudio ë…¸ë“œê°€ ë¶™ì„)
    file_prefix = f"bgm/shopping_bgm_{uuid.uuid4().hex[:6]}"
    if "78" in graph:
        graph["78"]["inputs"]["filename_prefix"] = file_prefix

    # ì‹¤í–‰
    try:
        res = _submit_and_wait_local(comfy_host, graph, timeout=600)  # ì˜¤ë””ì˜¤ ìƒì„±ì€ ì¢€ ê±¸ë¦´ ìˆ˜ ìˆìŒ

        # ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (move to out_path)
        outputs = res.get("outputs", {})
        for nid, out_d in outputs.items():
            if "audio" in out_d:
                for item in out_d["audio"]:
                    fname = item["filename"]
                    # ComfyUI output í´ë”ì—ì„œ ê°€ì ¸ì˜¤ê¸°
                    params = {"filename": fname, "subfolder": item.get("subfolder", ""),
                              "type": item.get("type", "output")}
                    resp = requests.get(f"{comfy_host}/view", params=params)
                    if resp.status_code == 200:
                        ensure_dir(out_path.parent)
                        with open(out_path, "wb") as f:
                            f.write(resp.content)
                        return True
        return False

    except Exception as e:
        print(f"âŒ BGM ìƒì„± ì‹¤íŒ¨: {e}")
        return False


# -----------------------------------------------------------------------------
# 2. ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜ (2-Step: Z-Image -> Qwen)
# -----------------------------------------------------------------------------


def build_shopping_images_2step(
        video_json_path: str | Path,
        *,
        ui_width: int = 720,
        ui_height: int = 1280,
        steps: int = 28,
        skip_if_exists: bool = True,
        on_progress: Optional[Callable[[Dict], None]] = None
) -> None:
    """
    [ìµœì¢… ìˆ˜ì •] ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜
    - ì›ì¹™: í”„ë¡¬í”„íŠ¸ëŠ” ë¬´ì¡°ê±´ 'video_shopping.json'(ì›ë³¸)ì—ì„œë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    - video.jsonì€ ìƒì„±ëœ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì €ì¥í•˜ëŠ” ìš©ë„ë¡œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    print(f"\n======== [Image Build Start (Source: video_shopping.json)] ========")
    print(f"Target: {video_json_path}")

    vpath = Path(video_json_path)
    product_dir = vpath.parent
    imgs_dir = ensure_dir(product_dir / "imgs")

    # 1. ì œí’ˆ ì´ë¯¸ì§€ ì°¾ê¸°
    product_json_path = product_dir / "product.json"
    product_img_file = None
    if product_json_path.exists():
        try:
            pj = json.loads(product_json_path.read_text(encoding="utf-8"))
            if pj.get("image_file"):
                pi = product_dir / pj["image_file"]
                if pi.exists():
                    product_img_file = pi
        except:
            pass

    if product_img_file:
        print(f"âœ… Product Image Found: {product_img_file.name}")
    else:
        print(f"âŒ Product Image NOT FOUND! Step 2 will be skipped.")

    # 2. [í•µì‹¬] ì›ë³¸ ë°ì´í„°(video_shopping.json) ë¡œë“œ -> í”„ë¡¬í”„íŠ¸ì˜ ìœ ì¼í•œ ì¶œì²˜
    shopping_source_map = {}
    shop_json_path = product_dir / "video_shopping.json"

    if not shop_json_path.exists():
        print(f"âŒ Critical Error: video_shopping.json not found!")
        if on_progress: on_progress({"msg": "âŒ ì›ë³¸ ë°ì´í„°(video_shopping.json)ê°€ ì—†ìŠµë‹ˆë‹¤."})
        return

    try:
        shop_data = load_json(shop_json_path, {})
        shop_scenes = shop_data.get("scenes", [])

        # ID ë§¤í•‘ (001, 1, t_001 ë“± ë‹¤ì–‘í•œ í¬ë§· ëŒ€ì‘)
        for ss in shop_scenes:
            raw_id = str(ss.get("id", ""))
            # ê·¸ëŒ€ë¡œ ì €ì¥
            shopping_source_map[raw_id] = ss
            # ìˆ«ìë§Œ ì¶”ì¶œí•´ì„œ ì €ì¥ (001 -> 1)
            if raw_id.isdigit():
                shopping_source_map[str(int(raw_id))] = ss
                shopping_source_map[f"t_{int(raw_id):03d}"] = ss
            # t_ ì œê±° ë²„ì „ ì €ì¥
            if raw_id.startswith("t_"):
                shopping_source_map[raw_id.replace("t_", "")] = ss

        print(f"âœ… Source Data Loaded: {len(shop_scenes)} scenes from video_shopping.json")
    except Exception as e:
        print(f"âŒ Failed to load video_shopping.json: {e}")
        return

    # 3. íƒ€ê²Ÿ ë°ì´í„°(video.json) ë¡œë“œ
    video_doc = load_json(vpath, {})
    scenes = video_doc.get("scenes", [])

    comfy_host = getattr(settings, "COMFY_HOST", "http://127.0.0.1:8188").rstrip("/")
    comfy_input_dir = Path(settings.COMFY_INPUT_DIR)
    comfy_input_dir.mkdir(parents=True, exist_ok=True)

    # -----------------------------------------------------------
    # Step 1: Z-Image Batch (ë² ì´ìŠ¤ ìƒì„±)
    # -----------------------------------------------------------
    if on_progress: on_progress({"msg": "=== [Step 1] ë² ì´ìŠ¤ ì´ë¯¸ì§€ ìƒì„± (Source ì°¸ì¡°) ==="})

    wf_z_path = Path(settings.JSONS_DIR) / "Z-Image-lora.json"
    if not wf_z_path.exists():
        wf_z_path = Path(r"C:\my_games\shorts_make\app\jsons\Z-Image-lora.json")

    if wf_z_path.exists():
        with open(wf_z_path, "r", encoding="utf-8") as f:
            graph_z_origin = json.load(f)

        for sc in scenes:
            sid = sc.get("id")
            temp_file = imgs_dir / f"temp_{sid}.png"

            # [í•µì‹¬] ë¬´ì¡°ê±´ ì›ë³¸(video_shopping.json)ì—ì„œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜´
            source_scene = shopping_source_map.get(sid)
            if not source_scene:
                # ë§¤í•‘ ì‹¤íŒ¨ ì‹œ ë‹¤ë¥¸ í‚¤ ì‹œë„
                if sid.startswith("t_"):
                    source_scene = shopping_source_map.get(sid.replace("t_", ""))
                    if not source_scene and sid.replace("t_", "").isdigit():
                        source_scene = shopping_source_map.get(str(int(sid.replace("t_", ""))))

            p1 = ""
            if source_scene:
                p1 = source_scene.get("prompt_img_1") or source_scene.get("prompt_img", "")

            if not p1:
                print(f"âš ï¸ [Step 1] No prompt in video_shopping.json for {sid} (Skipping)")
                continue

            # íŒŒì¼ ì¡´ì¬ ì‹œ ìŠ¤í‚µ
            if skip_if_exists and temp_file.exists() and temp_file.stat().st_size > 0:
                print(f"[Step 1] Skip existing: {sid}")
                continue

            if on_progress: on_progress({"msg": f"[Step 1] ë² ì´ìŠ¤ ìƒì„±: {sid}..."})
            print(f"[Step 1] Generating {sid} using prompt from Source...")

            graph = json.loads(json.dumps(graph_z_origin))
            for nid, node in graph.items():
                ctype = node.get("class_type", "")
                inputs = node.get("inputs", {})

                if ctype == "CLIPTextEncode" and nid == "6":
                    inputs["text"] = p1
                if "LatentImage" in ctype:
                    inputs["width"] = ui_width
                    inputs["height"] = ui_height
                if ctype == "KSampler" and "seed" in inputs:
                    inputs["seed"] = random.randint(1, 10 ** 9)
                    if "steps" in inputs: inputs["steps"] = steps
                if ctype == "PreviewImage":
                    node["class_type"] = "SaveImage"
                    node.setdefault("inputs", {})["filename_prefix"] = "Z_Base"

            try:
                res = _submit_and_wait_local(comfy_host, graph, on_progress=on_progress)
                outputs = res.get("outputs", {})
                found = False
                for _, out_d in outputs.items():
                    for img in out_d.get("images", []):
                        fname = img["filename"]
                        resp = requests.get(f"{comfy_host}/view", params={"filename": fname, "type": img["type"]})
                        with open(temp_file, "wb") as f:
                            f.write(resp.content)
                        found = True
                        break
                    if found: break
                if found:
                    print(f"âœ… [Step 1] Created: {temp_file.name}")
            except Exception as e:
                print(f"âŒ [Step 1] Error {sid}: {e}")

    # -----------------------------------------------------------
    # Step 2: Qwen Batch (ì œí’ˆ í•©ì„±)
    # -----------------------------------------------------------
    if on_progress: on_progress({"msg": "=== [Step 2] ì œí’ˆ í•©ì„± (Source ì°¸ì¡°) ==="})
    print("\n-------- Starting Step 2 (Qwen Edit) --------")

    wf_q_path = Path(settings.JSONS_DIR) / "QwenEdit2511-V1.json"
    if not wf_q_path.exists():
        wf_q_path = Path(r"C:\my_games\shorts_make\app\jsons\QwenEdit2511-V1.json")

    if not wf_q_path.exists() or not product_img_file:
        print("âŒ Step 2 Aborted: Missing workflow or product image.")
        return

    with open(wf_q_path, "r", encoding="utf-8") as f:
        graph_q_origin = json.load(f)

    prod_input_name = f"prod_{uuid.uuid4().hex[:6]}.png"
    shutil.copy2(product_img_file, comfy_input_dir / prod_input_name)

    for sc in scenes:
        sid = sc.get("id")
        final_file = imgs_dir / f"{sid}.png"
        temp_file = imgs_dir / f"temp_{sid}.png"

        # íŒŒì¼ ì¡´ì¬ ì‹œ ìŠ¤í‚µ
        if skip_if_exists and final_file.exists() and final_file.stat().st_size > 0:
            sc["img_file"] = str(final_file)
            print(f"[Step 2] Skip existing: {sid}")
            continue

        if not temp_file.exists():
            print(f"âš ï¸ [Step 2] Base image missing for {sid}. Skipping.")
            continue

        # [í•µì‹¬] ë¬´ì¡°ê±´ ì›ë³¸(video_shopping.json)ì—ì„œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜´
        source_scene = shopping_source_map.get(sid)
        if not source_scene:
            if sid.startswith("t_"):
                source_scene = shopping_source_map.get(sid.replace("t_", ""))
                if not source_scene and sid.replace("t_", "").isdigit():
                    source_scene = shopping_source_map.get(str(int(sid.replace("t_", ""))))

        raw_p2 = ""
        if source_scene:
            raw_p2 = source_scene.get("prompt_img_2") or ""

        if not raw_p2:
            print(f"  - No Prompt 2 in Source. Copying Step 1 image.")
            shutil.copy2(temp_file, final_file)
            sc["img_file"] = str(final_file)
            continue

        # [Auto-Fix] ì„ ìƒë‹˜ì´ ê°€ë¥´ì³ì£¼ì‹  ë¬¸ë²• ì ìš© ('from image 1' í•„ìˆ˜)
        p2_fixed = raw_p2
        if "from image 1" not in raw_p2.lower():
            pattern = re.compile(r"^(The|A|An)\s+([a-zA-Z0-9\s]+?)\s+(holding|has|is|with|placing|looking)",
                                 re.IGNORECASE)
            match = pattern.search(raw_p2)
            if match:
                p2_fixed = raw_p2.replace(match.group(2), f"{match.group(2)} from image 1", 1)
            else:
                p2_fixed = f"The subject from image 1 {raw_p2}"
            print(f"ğŸ”§ [Auto-Fix] {sid}: {p2_fixed}")
        else:
            print(f"ğŸ‘ [Prompt OK] {sid} (Source)")

        base_input_name = f"base_{sid}_{uuid.uuid4().hex[:6]}.png"
        shutil.copy2(temp_file, comfy_input_dir / base_input_name)

        graph = json.loads(json.dumps(graph_q_origin))

        if "9" in graph: graph["9"]["inputs"]["image"] = base_input_name
        if "32" in graph: graph["32"]["inputs"]["image"] = prod_input_name
        if "88" in graph: graph["88"]["inputs"]["value"] = p2_fixed

        for nid, node in graph.items():
            if node.get("class_type") == "PreviewImage":
                node["class_type"] = "SaveImage"
                node.setdefault("inputs", {})["filename_prefix"] = "ShopFinal"

        if on_progress: on_progress({"msg": f"[Step 2] í•©ì„± ì§„í–‰({sid})..."})
        try:
            res = _submit_and_wait_local(comfy_host, graph, on_progress=on_progress)
            outputs = res.get("outputs", {})
            found = False
            for _, out_d in outputs.items():
                for img in out_d.get("images", []):
                    fname = img["filename"]
                    resp = requests.get(f"{comfy_host}/view", params={"filename": fname, "type": img["type"]})
                    with open(final_file, "wb") as f:
                        f.write(resp.content)
                    sc["img_file"] = str(final_file)
                    found = True
                    break
                if found: break

            if found:
                print(f"âœ… Scene {sid} Synthesis Done.")
            else:
                print(f"âŒ Scene {sid} Failed (No output).")

        except Exception as e:
            print(f"âŒ Scene {sid} Error: {e}")

    # ìµœì¢… ê²°ê³¼ ì—…ë°ì´íŠ¸ (ì´ë¯¸ì§€ ê²½ë¡œ ë“±)
    try:
        with open(vpath, "w", encoding="utf-8") as f:
            json.dump(video_doc, f, indent=2, ensure_ascii=False)
    except:
        pass

    print("======== [Image Build End] ========\n")


# -----------------------------------------------------------------------------
# 3. ì˜µì…˜ ë°ì´í„° í´ë˜ìŠ¤
# -----------------------------------------------------------------------------
@dataclass
class BuildOptions:
    scene_count: int = 6
    style: str = "news_hook"
    hook_level: int = 3
    fps: int = 24
    allow_fallback_rule: bool = True


# -----------------------------------------------------------------------------
# 4. JSON ë¹Œë”
# -----------------------------------------------------------------------------

class ShoppingVideoJsonBuilder:
    def __init__(self, on_progress: Optional[Callable[[str], None]] = None):
        self.on_progress = on_progress or (lambda msg: None)
        self.ai = AI()

    def create_draft(self, product_dir: str | Path, product_data: Dict[str, Any], options: BuildOptions) -> Path:
        """[1ë‹¨ê³„] ê¸°íš ì´ˆì•ˆ - BGM ê¸°íš ì¶”ê°€ + [ìˆ˜ì •] ì‹œê°ì  í™˜ê°(ë¡œê³ /QR) ë°©ì§€"""
        p_dir = Path(product_dir)
        vpath = p_dir / "video_shopping.json"

        product_name = product_data.get("product_name", "ìƒí’ˆëª… ì—†ìŒ")
        desc = product_data.get("description") or product_data.get("summary_source") or ""

        self.on_progress(f"[Draft] AI ê¸°íš ì‹œì‘ (ìƒí’ˆ: {product_name})...")

        # BGM ê°€ì´ë“œ (ê¸°ì¡´ ë™ì¼)
        bgm_guide = (
            "4. **Background Music (BGM)**: \n"
            "   - Design a prompt for audio generation.\n"
            "   - Format: 'instrumental, background music, [Mood], [Genre], [Instruments], [Tempo], [Energy]'.\n"
            "   - **NO Vocals**: Do not use words like song, singing, voice.\n"
            "   - **NO Model Name**: Do NOT include the word 'Ace-Step' in the output prompt.\n"
            "   - Example: 'instrumental, background music, bright, acoustic pop, guitar, piano, medium tempo, uplifting'."
        )

        # [ìˆ˜ì •] ì‹œê°ì  ì œì•½ì‚¬í•­(Visual Constraints) ê°•ë ¥ ì¶”ê°€
        visual_rules = (
            "5. **Visual Description Rules (Clean Prompt)**:\n"
            "   - Focus ONLY on the **Situation, Action, and Background**.\n"
            "   - **FORBIDDEN**: Do NOT describe specific product details like 'Logo', 'Text', 'QR Code', 'Specific Color', 'Label'.\n"
            "   - Bad: 'Product with a red logo spinning.' -> Good: 'The product spinning on the table.'\n"
            "   - Reason: The actual product image will be composited later, so text descriptions of details cause hallucinations."
        )

        system_prompt = (
            "ë‹¹ì‹ ì€ AI ì˜ìƒ ìƒì„±(I2V)ì„ ìœ„í•œ ìˆí¼ ê¸°íš ì „ë¬¸ê°€ì´ì ìŒì•… ê°ë…ì…ë‹ˆë‹¤. "
            "ìƒí’ˆì„ ë¶„ì„í•˜ì—¬ ê¸°íšì•ˆì„ ì‘ì„±í•˜ì„¸ìš”.\n\n"
            "**[í•„ìˆ˜ ì‹œê°í™” ê·œì¹™]**\n"
            "1. **One Scene = One Action**: í•œ ì¥ë©´ì—ëŠ” ì˜¤ì§ 'í•˜ë‚˜ì˜ ë™ì‘'ë§Œ ë¬˜ì‚¬.\n"
            "2. **No Split Screens**: ì „ì²´ í™”ë©´ êµ¬ì„±.\n"
            "3. **Focus on Impact**: ê²°ì •ì  ìˆœê°„ í¬ì°©.\n"
            f"{bgm_guide}\n"
            f"{visual_rules}"
        )

        user_prompt = f"""
        [ìƒí’ˆ ì •ë³´]
        - ìƒí’ˆëª…: {product_name}
        - ì„¤ëª…: {desc}

        [ì œì‘ ê°€ì´ë“œ]
        1. ì´ ì¥ë©´: {options.scene_count}ê°œ
        2. ìŠ¤íƒ€ì¼: {options.style}

        [ì¶œë ¥ í¬ë§· (JSON)]
        {{
            "meta": {{ 
                "title": "...", 
                "voice_gender": "female", 
                "character_prompt": "...", 
                "bgm_prompt": "instrumental, background music, ... (English Only)"
            }},
            "scenes": [
                {{
                    "id": "001",
                    "banner": "...",
                    "prompt": "í™”ë©´ ë¬˜ì‚¬ (í•œê¸€, ì ˆëŒ€ ì‹œí€€ìŠ¤/ë‹¨ê³„ ë‚˜ì—´ ê¸ˆì§€, ë‹¨ì¼ ë™ì‘ ìœ„ì£¼, ë¡œê³ /í…ìŠ¤íŠ¸ ë¬˜ì‚¬ ê¸ˆì§€)",
                    "narration": "ì‹¤ì œ ì½ì„ ëŒ€ì‚¬ (ì§€ì‹œë¬¸ ì œì™¸)",
                    "sfx": "íš¨ê³¼ìŒ",
                    "voice_config": {{
                        "speed": 1.0, 
                        "emotion": {{ "neutral": 1.0, "happy": 0.0, "sad": 0.0, "disgust": 0.0, "fear": 0.0, "surprise": 0.0, "anger": 0.0, "other": 0.0 }}
                    }},
                    "subtitle": "..."
                }},
                ...
            ]
        }}
        """

        try:
            resp_text = self.ai.ask_smart(system_prompt, user_prompt, prefer="openai")
            data = self._safe_json_parse(resp_text)
        except Exception as e:
            self.on_progress(f"âŒ ì´ˆì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")
            raise

        final_json = {
            "schema": "shopping_shorts_v2",
            "style": options.style,
            "product": product_data,
            "meta": data.get("meta", {}),
            "defaults": {"image": {"width": 720, "height": 1280}, "movie": {"fps": options.fps}},
            "audit": {"created_at": _now_str(), "step": "draft"},
            "scenes": []
        }

        imgs_dir = p_dir / "imgs"
        clips_dir = p_dir / "clips"
        voice_dir = p_dir / "voice"
        ensure_dir(imgs_dir)
        ensure_dir(clips_dir)
        ensure_dir(voice_dir)

        for idx, sc in enumerate(data.get("scenes", [])):
            sid = sc.get("id") or f"{idx + 1:03d}"
            new_scene = {
                "id": sid,
                "banner": sc.get("banner"),
                "prompt": sc.get("prompt", ""),
                "narration": sc.get("narration", ""),
                "sfx": sc.get("sfx", ""),
                "voice_config": sc.get("voice_config", {"speed": 1.0, "emotion": {"neutral": 1.0}}),
                "subtitle": sc.get("subtitle", ""),
                "seconds": 0,
                "prompt_img_1": "",
                "prompt_img_2": "",
                "prompt_movie": "",
                "prompt_negative": "",
                "img_file": str(imgs_dir / f"{sid}.png"),
                "movie_file": str(clips_dir / f"{sid}.mp4"),
                "voice_file": str(voice_dir / f"{sid}.wav")
            }
            final_json["scenes"].append(new_scene)

        save_json(vpath, final_json)
        self.on_progress(f"[Draft] ì´ˆì•ˆ ì™„ë£Œ. BGM: {final_json['meta'].get('bgm_prompt')}")
        return vpath

    def enrich_video_json(self, video_json_path: str | Path, product_data: Dict[str, Any]) -> Path:
        """
        [3ë‹¨ê³„] ìƒì„¸í™” (ìŒì„± -> BGM -> ì˜ì–´ í”„ë¡¬í”„íŠ¸)
        [ìˆ˜ì •] Qwen ëª¨ë¸ ì „ìš© ë¬¸ë²•("Subject from image 1...") ê°•ì œ ì ìš©
        """
        vpath = Path(video_json_path)
        p_dir = vpath.parent
        voice_dir = ensure_dir(p_dir / "voice")
        bgm_path = p_dir / "bgm.mp3"

        data = load_json(vpath, {})
        scenes = data.get("scenes", [])
        meta = data.get("meta", {})

        # ---------------------------------------------------------------------
        # 1. ìŒì„± ìƒì„± (ê¸°ì¡´ ìœ ì§€)
        # ---------------------------------------------------------------------
        gender = meta.get("voice_gender", "female").lower()
        if "male" == gender:
            ref_voice = Path(r"C:\my_games\shorts_make\voice\ë‚¨ìì„±ìš°1.mp3")
        else:
            ref_voice = Path(r"C:\my_games\shorts_make\voice\ê¼¬ê¼¬ ìŒì„±.m4a")

        self.on_progress(f"[Enrich] 1/3ë‹¨ê³„: ìŒì„± ìƒì„± ({gender}) ë° ì •ë°€ ì¸¡ì •...")
        comfy_host = getattr(settings, "COMFY_HOST", "http://127.0.0.1:8188")
        total_dur = 0.0

        for sc in scenes:
            sid = sc["id"]
            config = _get_zonos_config(sc, self.ai)
            narr = sc.get("narration", "").strip()
            v_path = Path(sc.get("voice_file") or str(voice_dir / f"{sid}.wav"))

            if not narr:
                if sc.get("seconds", 0) == 0: sc["seconds"] = 3
                total_dur += sc["seconds"]
                continue

            if not v_path.exists() or v_path.stat().st_size == 0:
                self.on_progress(f"   ğŸ™ï¸ Scene {sid} ìŒì„± ìƒì„±...")
                success = generate_tts_zonos(narr, v_path, ref_voice, comfy_host, config)
                if not success:
                    sc["seconds"] = 4
                else:
                    final_dur = 0.0
                    for _ in range(5):
                        try:
                            d = get_audio_duration(str(v_path))
                            if d > 0:
                                final_dur = d
                                break
                        except:
                            pass
                        time.sleep(0.2)
                    sc["seconds"] = round(final_dur + 0.5, 2) if final_dur > 0 else 4

            total_dur += sc["seconds"]
            sc["voice_file"] = str(v_path)

        data.setdefault("meta", {})["total_duration"] = round(total_dur, 2)
        save_json(vpath, data)

        # ---------------------------------------------------------------------
        # 2. BGM ìƒì„± (ê¸°ì¡´ ìœ ì§€)
        # ---------------------------------------------------------------------
        bgm_prompt = meta.get("bgm_prompt", "")
        if not bgm_prompt:
            bgm_prompt = "instrumental, background music, calm, minimal, piano, soft, loopable"
            meta["bgm_prompt"] = bgm_prompt

        if bgm_path.exists() and bgm_path.stat().st_size > 1024:
            self.on_progress(f"[Enrich] 2/3ë‹¨ê³„: BGM ì´ë¯¸ ì¡´ì¬ (ìŠ¤í‚µ).")
        else:
            self.on_progress(f"[Enrich] 2/3ë‹¨ê³„: BGM ìƒì„± ì¤‘...")
            success_bgm = generate_bgm_acestep(
                prompt=bgm_prompt,
                out_path=bgm_path,
                duration_sec=total_dur,
                comfy_host=comfy_host,
            )
            if success_bgm:
                self.on_progress("   âœ… BGM ìƒì„± ì™„ë£Œ!")
            else:
                self.on_progress("   âŒ BGM ìƒì„± ì‹¤íŒ¨ (ë¡œê·¸ í™•ì¸).")

        # ---------------------------------------------------------------------
        # 3. í”„ë¡¬í”„íŠ¸ ìƒì„¸í™” (ë¬¸ë²• ëŒ€ìˆ˜ìˆ )
        # ---------------------------------------------------------------------
        self.on_progress("[Enrich] 3/3ë‹¨ê³„: ë¹„ì£¼ì–¼ í”„ë¡¬í”„íŠ¸ ê³ ë„í™” (Qwen ë¬¸ë²• ì ìš©)...")

        char_prompt = meta.get("character_prompt", "Young Korean model")
        if "male" == gender:
            gender_kw = "male, man, 1boy"
        else:
            gender_kw = "female, woman, 1girl"

        scene_texts = []
        for sc in scenes:
            sfx_info = f" (SFX: {sc.get('sfx')})" if sc.get("sfx") else ""
            scene_texts.append(f"- Scene {sc['id']} (ì§€ë¬¸): {sc.get('prompt')}{sfx_info}")

        # [í•µì‹¬] Qwen ëª¨ë¸ì´ ì•Œì•„ë¨¹ëŠ” ë¬¸ë²• ê°•ì œ
        sys_p = (
            "You are a ComfyUI Compositing Director using Qwen-Edit.\n"
            "Your task is to generate 2-step prompts. Step 2 requires a VERY SPECIFIC grammar to work.\n\n"
            "**[CRITICAL RULE FOR Step 2]**\n"
            "You MUST explicitly identify the subject in Image 1 and the object in Image 2.\n"
            "**Syntax:** \"[Subject] from image 1 [action] [object] from image 2\"\n"
            "**Examples:**\n"
            "- \"The woman from image 1 holds the object from image 2 in her hand.\"\n"
            "- \"The table from image 1 has the object from image 2 placed on it.\"\n"
            "- \"The man from image 1 is looking at the object from image 2.\"\n\n"
            "**Language:** English Only. No Korean."
        )

        user_p = f"""
        [Prompting Strategy]

        **Context**:
        - Character: "{char_prompt}" ({gender_kw})

        Analyze each scene and apply these rules:

        ### 1. `prompt_img_1` (Canvas)
        - Describe background, lighting, and character pose.
        - **IMPORTANT**: Leave space for the product (e.g., "empty hand", "empty table space").
        - **NO Product Details**: Do not describe the product itself.

        ### 2. `prompt_img_2` (Paint / Qwen)
        - **STRICT GRAMMAR**: You MUST use "from image 1" for the subject/background AND "from image 2" for the product.
        - **Format (Person)**: "The {gender_kw} from image 1 holds the object from image 2 in hand."
        - **Format (Background)**: "The surface from image 1 has the object from image 2 placed on it."
        - **Format (Action)**: "The {gender_kw} from image 1 throws the object from image 2."
        - **NO Adjectives for Product**: Do not say "red bottle". Just say "object from image 2".

        ### 3. `prompt_negative`
        - Standard: "text, watermark, logo, deformed hands, extra fingers, product details".

        ### 4. `prompt_movie`
        - Camera movement description (English).

        [Input Scenarios]
        {chr(10).join(scene_texts)}

        [Output Format (JSON)]
        {{
            "scenes": {{
                "001": {{ "prompt_img_1": "...", "prompt_img_2": "...", "prompt_negative": "...", "prompt_movie": "..." }},
                ...
            }}
        }}
        """

        try:
            resp = self.ai.ask_smart(sys_p, user_p, prefer="openai")
            enriched = self._safe_json_parse(resp)
            en_map = enriched.get("scenes", {})

            if isinstance(en_map, list):
                en_map = {item.get("id", f"t_{i + 1:03d}"): item for i, item in enumerate(en_map)}

            for sc in scenes:
                sid = sc["id"]
                tgt = None
                candidates = [sid, sid.lstrip("0"), f"Scene {sid}", f"t_{sid}", sid.replace("t_", "")]

                for key in candidates:
                    if key in en_map:
                        tgt = en_map[key]
                        break

                if not tgt:
                    for val in en_map.values():
                        if isinstance(val, dict) and str(val.get("id", "")) == sid:
                            tgt = val
                            break

                if tgt:
                    sc["prompt_img_1"] = tgt.get("prompt_img_1", "")
                    sc["prompt_img_2"] = tgt.get("prompt_img_2", "")
                    sc["prompt_negative"] = tgt.get("prompt_negative", "")
                    sc["prompt_movie"] = tgt.get("prompt_movie", "")
                    sc["prompt_img"] = sc["prompt_img_1"]

            data["audit"]["enriched_at"] = _now_str()
            data["audit"]["step"] = "enriched"

            save_json(vpath, data)
            self.on_progress(f"[Enrich] ìƒì„¸í™” ì™„ë£Œ (Qwen ë¬¸ë²• ì ìš©ë¨).")

        except Exception as e:
            self.on_progress(f"âŒ ìƒì„¸í™” ì‹¤íŒ¨: {e}")

        return vpath

    def _safe_json_parse(self, text: str) -> Dict:
        try:
            text = re.sub(r"```json", "", text, flags=re.I).replace("```", "")
            return json.loads(text)
        except:
            s, e = text.find("{"), text.rfind("}")
            if s != -1 and e != -1:
                return json.loads(text[s:e + 1])
            raise ValueError("Invalid JSON response")


# -----------------------------------------------------------------------------
# 5. ì´ë¯¸ì§€ ìƒì„±ê¸°
# -----------------------------------------------------------------------------
class ShoppingImageGenerator:
    def __init__(self, on_progress: Optional[Callable[[str], None]] = None):
        self.on_progress = on_progress or (lambda msg: None)

    def generate_images(self, video_json_path: str | Path, skip_if_exists: bool = True) -> None:
        def _cb(d):
            self.on_progress(d.get("msg", ""))

        # 1. í•´ìƒë„ ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’ ì•ˆì „ì¥ì¹˜ í¬í•¨)
        img_size = settings.DEFAULT_IMG_SIZE
        width_val = img_size[0]  # ê°€ë¡œ
        height_val = img_size[1]  # ì„¸ë¡œ

        # 2. ìŠ¤í… ìˆ˜ ê°€ì ¸ì˜¤ê¸°
        steps_val = settings.DEFAULT_T2I_STEPS

        try:
            build_shopping_images_2step(
                video_json_path=video_json_path,
                ui_width=width_val,  # settingsì—ì„œ ê°€ì ¸ì˜¨ ê°€ë¡œê°’
                ui_height=height_val,  # settingsì—ì„œ ê°€ì ¸ì˜¨ ì„¸ë¡œê°’
                steps=steps_val,  # settingsì—ì„œ ê°€ì ¸ì˜¨ ìŠ¤í… ìˆ˜
                on_progress=_cb
            )
        except Exception as e:
            self.on_progress(f"âŒ ì´ë¯¸ì§€ ìƒì„± ì˜¤ë¥˜: {e}")
            raise e

# -----------------------------------------------------------------------------
# 6. ì˜ìƒ ìƒì„±/ë³‘í•©ê¸°
# -----------------------------------------------------------------------------
class ShoppingMovieGenerator:
    def __init__(self, on_progress: Optional[Callable[[str], None]] = None):
        self.on_progress = on_progress or (lambda msg: None)

    def generate_movies(self, video_json_path: str | Path, skip_if_exists: bool = True, fps: int = 24) -> None:
        vpath = Path(video_json_path)  # ì´ê²ƒì€ video_shopping.json ì…ë‹ˆë‹¤.
        project_dir = vpath.parent

        # [ì¤‘ìš”] I2V ì—”ì§„(build_shots_with_i2v)ì€ ë¬´ì¡°ê±´ 'video.json'ì„ ì°¾ìŠµë‹ˆë‹¤.
        # ë”°ë¼ì„œ video_shopping.json ë‚´ìš©ì„ ë³µì‚¬í•œ 'ì„ì‹œ íŒŒì¼'ì„ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.
        temp_video_json = project_dir / "video.json"

        self.on_progress(f"[Movie] I2V ì¤€ë¹„: {vpath.name}")

        # 1. video_shopping.json ë‚´ìš©ì„ ì½ìŒ
        data = load_json(vpath, {})

        # 2. duration ì•ˆì „ì¥ì¹˜ (0ì´ë©´ ê¸°ë³¸ê°’ ë¶€ì—¬)
        for sc in data.get("scenes", []):
            if float(sc.get("duration", 0)) <= 0:
                sc["duration"] = float(sc.get("seconds", 4.0))

        # 3. ì„ì‹œ íŒŒì¼(video.json)ë¡œ ì €ì¥ -> ì—”ì§„ì´ ì´ê±¸ ì½ìŒ
        save_json(temp_video_json, data)

        def _cb(d):
            self.on_progress(d.get("msg", ""))

        try:
            # 4. ì—”ì§„ ì‹¤í–‰ (ì—”ì§„ì€ í´ë” ë‚´ì˜ video.jsonì„ ìë™ìœ¼ë¡œ ì°¾ìŒ)
            build_shots_with_i2v(str(project_dir), total_frames=0, ui_fps=fps, on_progress=_cb)
            self.on_progress("[Movie] ìƒì„± ì™„ë£Œ")
        finally:
            # 5. [í•„ìˆ˜] ì‘ì—…ì´ ëë‚˜ë©´ ì„ì‹œ íŒŒì¼(video.json)ì€ í—·ê°ˆë¦¬ì§€ ì•Šê²Œ ì‚­ì œ
            if temp_video_json.exists():
                try:
                    os.remove(temp_video_json)
                    # self.on_progress("â„¹ï¸ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
                except:
                    pass

    def merge_movies(self, video_json_path: str | Path):
        vpath = Path(video_json_path)
        project_dir = vpath.parent
        clips_dir = project_dir / "clips"

        self.on_progress("[Merge] ì˜ìƒ í•©ì¹˜ê¸°...")
        data = load_json(vpath, {})
        clip_paths = []
        for sc in data.get("scenes", []):
            cpath = clips_dir / f"{sc['id']}.mp4"
            if cpath.exists():
                clip_paths.append(cpath)

        if not clip_paths:
            self.on_progress("âŒ ë³‘í•©í•  í´ë¦½ ì—†ìŒ")
            return

        out_path = project_dir / "final_shopping_video.mp4"
        ffmpeg_exe = getattr(settings, "FFMPEG_EXE", "ffmpeg")
        concatenate_scene_clips(clip_paths, out_path, ffmpeg_exe)
        self.on_progress(f"âœ… ë³‘í•© ì™„ë£Œ: {out_path.name}")


# -----------------------------------------------------------------------------
# 7. íŒŒì´í”„ë¼ì¸
# -----------------------------------------------------------------------------
class ShoppingShortsPipeline:
    def __init__(self, on_progress: Optional[Callable[[str], None]] = None):
        self.on_progress = on_progress or (lambda msg: None)

    def run_all(
            self,
            product_dir: str | Path,
            product_data: Dict[str, Any],
            options: Optional[BuildOptions] = None,
            build_json: bool = True,
            build_images: bool = True,
            build_movies: bool = True,
            merge: bool = True,
            skip_if_exists: bool = True,
    ) -> Path:
        options = options or BuildOptions()
        vpath = Path(product_dir) / "video_shopping.json"

        builder = ShoppingVideoJsonBuilder(self.on_progress)

        if build_json:
            if not vpath.exists():
                vpath = builder.create_draft(product_dir, product_data, options)
            builder.enrich_video_json(vpath, product_data)

        if build_images:
            img_gen = ShoppingImageGenerator(self.on_progress)
            img_gen.generate_images(vpath, skip_if_exists)

        if build_movies:
            mov_gen = ShoppingMovieGenerator(self.on_progress)
            mov_gen.generate_movies(vpath, skip_if_exists, fps=options.fps)

        if merge:
            mov_gen = ShoppingMovieGenerator(self.on_progress)
            mov_gen.merge_movies(vpath)

        return vpath


def convert_shopping_to_video_json_with_ai(
        project_dir: str,
        ai_client: Any = None,
        fps: int = 30,
        width: int = 1080,
        height: int = 1920,
        steps: int = 20,
        on_progress: Optional[Callable[[Dict[str, Any]], None]] = None
) -> str:
    """
    [ì‡¼í•‘->ì‡¼ì¸  ë³€í™˜]
    video_shopping.jsonì„ ì½ì–´ì„œ Shorts íƒ­ê³¼ í˜¸í™˜ë˜ëŠ” video.jsonì„ ìƒì„±í•©ë‹ˆë‹¤.
    UIì—ì„œ ì…ë ¥ë°›ì€ FPS, í•´ìƒë„, Steps ê°’ì„ video.jsonì— ì˜êµ¬ ì €ì¥í•©ë‹ˆë‹¤.
    """

    def _log(msg: str):
        if on_progress:
            on_progress({"msg": msg})
        print(f"[ShoppingConverter] {msg}")

    proj_path = Path(project_dir)
    src_json_path = proj_path / "video_shopping.json"
    dst_json_path = proj_path / "video.json"

    if not src_json_path.exists():
        raise FileNotFoundError(f"video_shopping.jsonì´ ì—†ìŠµë‹ˆë‹¤: {src_json_path}")

    # 1. ì‡¼í•‘ ë°ì´í„° ë¡œë“œ
    try:
        with open(src_json_path, "r", encoding="utf-8") as f:
            src_data = json.load(f)
    except Exception as e:
        raise ValueError(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")

    _log("ë°ì´í„° êµ¬ì¡° ë³€í™˜ ì‹œì‘...")

    # 2. ê¸°ë³¸ ì •ë³´ ë§¤í•‘
    prod = src_data.get("product", {})
    project_name = prod.get("product_name") or src_data.get("project_name", "Shopping Project")
    src_scenes = src_data.get("scenes", [])
    if not src_scenes:
        src_scenes = src_data.get("groups", [])

    # 3. video.json ì”¬ ë¦¬ìŠ¤íŠ¸ ì¡°ë¦½
    new_scenes = []
    current_time = 0.0
    full_lyrics_parts = []

    for idx, sc in enumerate(src_scenes):
        # =========================================================================
        # [ìˆ˜ì •] ID í†µì¼ì„± ìœ ì§€: ì›ë³¸ IDê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©, ì—†ìœ¼ë©´ t_001 ìƒì„±
        # ì´ë ‡ê²Œ í•´ì•¼ ì´ë¯¸ì§€ íŒŒì¼ëª…(001.png vs t_001.png) ë¶ˆì¼ì¹˜ê°€ ì‚¬ë¼ì§
        # =========================================================================
        original_id = str(sc.get("id", "")).strip()
        if original_id:
            scene_id = original_id
        else:
            scene_id = f"t_{idx + 1:03d}"

        dur = float(sc.get("seconds") or sc.get("duration") or 4.0)
        start_t = current_time
        end_t = current_time + dur
        current_time = end_t

        narration = str(sc.get("narration") or sc.get("narration_text") or "")
        full_lyrics_parts.append(narration)

        new_scene = {
            "id": scene_id,
            "section": "main",
            "start": round(start_t, 3),
            "end": round(end_t, 3),
            "duration": round(dur, 3),
            "img_file": sc.get("img_file") or sc.get("image_path") or "",
            "voice_file": sc.get("voice_file") or sc.get("audio_path") or "",
            "lyric": narration,
            "prompt": sc.get("prompt", ""),
            "prompt_movie": sc.get("prompt_movie", ""),
            "prompt_img": sc.get("prompt_img", ""),
            "prompt_negative": sc.get("prompt_negative", ""),
            "effect": [],
            "screen_transition": (idx == len(src_scenes) - 1)
        }
        new_scenes.append(new_scene)

    total_duration = current_time
    full_lyrics = "\n".join(full_lyrics_parts)

    # 4. video.json ë¼ˆëŒ€ ì €ì¥ (UI ì„¤ì •ê°’ ë°˜ì˜)
    video_data = {
        "title": project_name,
        "duration": round(total_duration, 3),
        "fps": fps,  # [UIê°’] ìµœìƒìœ„ FPS ì €ì¥
        "lyrics": full_lyrics,
        "scenes": new_scenes,
        "defaults": {
            "movie": {
                "fps": fps,
                "target_fps": fps,
                "input_fps": fps
            },
            "image": {
                "width": width,  # [UIê°’] í•´ìƒë„ ì €ì¥
                "height": height,  # [UIê°’] í•´ìƒë„ ì €ì¥
                "fps": fps
            },
            # [New] ìƒì„± ê´€ë ¨ íŒŒë¼ë¯¸í„° ì €ì¥
            "generator": {
                "steps": steps
            }
        },
        "audit": {
            "source": "shopping_converter_v2",
            "converted_at": str(datetime.datetime.now())
        }
    }

    with open(dst_json_path, "w", encoding="utf-8") as f:
        json.dump(video_data, f, indent=2, ensure_ascii=False)

    _log(f"video.json ì €ì¥ ì™„ë£Œ (FPS: {fps}, Size: {width}x{height}, Steps: {steps})")
    _log("AI ìƒì„¸í™” ì§„í–‰...")

    # 5. AI ìƒì„¸í™” (ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±)
    if ai_client:
        try:
            def ask_wrapper(sys_msg, user_msg):
                return ai_client.ask_smart(sys_msg, user_msg, prefer="openai")

            fill_prompt_movie_with_ai(
                str(dst_json_path.parent),
                ask_wrapper,
                log_fn=_log
            )
            _log("âœ… AI ìƒì„¸í™”(Segments/Prompts) ì™„ë£Œ.")
        except Exception as e:
            _log(f"âŒ AI ìƒì„¸í™” ì‹¤íŒ¨: {e}")

    return str(dst_json_path)
#