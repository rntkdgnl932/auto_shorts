import google.generativeai as genai
from google.generativeai.types import RequestOptions
import google.api_core.exceptions as gax
import random
from typing import Any, Optional, TypedDict, Tuple
import time
import re
import settings

import requests
from xmlrpc import client as xmlrpc_client

class RespOut(TypedDict):
    text: Optional[str]
    blocked: bool
    finish_reason: Optional[str]
    block_reason: Optional[str]
    safety_ratings: Any
    has_parts: bool


def call_gemini(prompt, temperature=0.6, is_json=False, max_retries=5):
    """
    ë°˜í™˜:
      - ì„±ê³µ: str(response_text)
      - SAFETY ì°¨ë‹¨: "SAFETY_BLOCKED"
      - ì‹¤íŒ¨: "API_ERROR"
    """
    model_name = "gemini-2.0-flash"
    safety_settings = {
        "HARM_CATEGORY_HARASSMENT": "BLOCK_NONE",
        "HARM_CATEGORY_HATE_SPEECH": "BLOCK_NONE",
        "HARM_CATEGORY_SEXUALLY_EXPLICIT": "BLOCK_NONE",
        "HARM_CATEGORY_DANGEROUS_CONTENT": "BLOCK_NONE",
    }
    generation_config = genai.types.GenerationConfig(
        temperature=temperature,
        response_mime_type="application/json" if is_json else "text/plain",
        candidate_count=1,
        # í•„ìš”ì‹œ ìµœëŒ€ í† í° ì œí•œ:
        max_output_tokens=4000,
        # top_p=0.9,
    )
    request_options = RequestOptions(timeout=300)

    for attempt in range(max_retries):
        try:
            print(
                f"â–¶ [Gemini] ì‹œë„ {attempt + 1}/{max_retries} | model={model_name} | json={is_json} | temp={temperature}",
                flush=True)

            model = genai.GenerativeModel(model_name)
            resp = model.generate_content(
                [{"role": "user", "parts": [{"text": prompt}]}],  # ê¶Œì¥ í¬ë§·
                generation_config=generation_config,
                safety_settings=safety_settings,
                request_options=request_options,
            )

            ex = _extract_text_from_parts(resp)
            print(f"   â”œâ”€ finish_reason={ex['finish_reason']} | blocked={ex['blocked']} | has_parts={ex['has_parts']}")

            if ex["blocked"]:
                print(f"   â”œâ”€ SAFETY ì°¨ë‹¨(block_reason={ex['block_reason']}) â†’ ì¤‘ë‹¨")
                return "SAFETY_BLOCKED"

            # ì •ìƒ í…ìŠ¤íŠ¸
            if ex["text"]:
                print(f"âœ… ì‘ë‹µ ìˆ˜ì‹  (ê¸¸ì´={len(ex['text'])})")
                return ex["text"]

            # parts ì—†ìŒ/ë¹ˆ í…ìŠ¤íŠ¸ì¸ë° finish_reason=STOP â†’ JSON ëª¨ë“œì¼ ê²½ìš° ì €ì˜¨ ì¬í”„ë¡¬í”„íŠ¸ 1íšŒ
            if is_json:
                print("âš ï¸ í›„ë³´ëŠ” ìˆìœ¼ë‚˜ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŒ â†’ ì €ì˜¨ ì¬í”„ë¡¬í”„íŠ¸ ì‹œë„(1íšŒ)")
                fixed = _low_temp_json_reprompt(model_name, prompt, request_options)
                if fixed and fixed.strip():
                    print(f"âœ… ì €ì˜¨ ì¬í”„ë¡¬í”„íŠ¸ ì„±ê³µ (ê¸¸ì´={len(fixed)})")
                    return fixed
                else:
                    print("   â””â”€ ì €ì˜¨ ì¬í”„ë¡¬í”„íŠ¸ ì‹¤íŒ¨ â†’ ì¬ì‹œë„ ë£¨í”„ë¡œ ì´ë™")
            else:
                print("âš ï¸ í›„ë³´ëŠ” ìˆìœ¼ë‚˜ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŒ â†’ ì¬ì‹œë„ ëŒ€ìƒ")

        except Exception as exc:
            et = type(exc).__name__
            print(f"âŒ ì˜ˆì™¸ ë°œìƒ [{et}]: {exc}")
            if not _is_retryable_exception(exc):
                print("ğŸš« ì¬ì‹œë„ ë¹„ëŒ€ìƒ ì˜¤ë¥˜ â†’ ì¦‰ì‹œ ì‹¤íŒ¨")
                return "API_ERROR"

        # ì¬ì‹œë„ ì „ ëŒ€ê¸° (ë§ˆì§€ë§‰ ì‹œë„ëŠ” ëŒ€ê¸°/ì¶œë ¥ ìƒëµ)
        if attempt < max_retries - 1:
            wait = _backoff(attempt)  # ê¸°ì¡´ ê³„ì‚° ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì§€í„° í¬í•¨)
            # printë¡œë§Œ ì•Œë¦¬ì§€ ë§ê³ , ì‹¤ì œë¡œ ê·¸ ì‹œê°„ë§Œí¼ ì •í™•íˆ ì”ë‹¤
            sleep_with_exact(wait, label=f"attempt {attempt + 1} â†’ {attempt + 2}")
        else:
            # ë§ˆì§€ë§‰ ì‹œë„: ì¬ì‹œë„ ì—†ìŒ, ëŒ€ê¸°/ì¶œë ¥ ê¸ˆì§€
            pass

    print("âŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ â†’ ì‹¤íŒ¨ ì²˜ë¦¬")
    return "API_ERROR"


def _extract_text_from_parts(resp: Any) -> RespOut:
    """
    Gemini SDK ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸/ë©”íƒ€ ì •ë³´ë¥¼ 'ì•ˆì „í•˜ê²Œ' ì¶”ì¶œí•©ë‹ˆë‹¤.
    - response.text ì—ëŠ” ì ‘ê·¼í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (SDKì— ë”°ë¼ ValueError ë°œìƒ).
    - candidates[0].content.parts ë¥¼ ì‹ ë¢°í•´ì„œ ë¬¸ìì—´ì„ ëª¨ìë‹ˆë‹¤.
    - SAFETY ì°¨ë‹¨ ì—¬ë¶€, finish_reason, block_reason, safety_ratings, parts ì¡´ì¬ ì—¬ë¶€ë¥¼ í•¨ê»˜ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    out: RespOut = {
        "text": None,
        "blocked": False,
        "finish_reason": None,
        "block_reason": None,
        "safety_ratings": None,
        "has_parts": False,
    }

    try:
        # prompt_feedbackì—ì„œ ì°¨ë‹¨ ì‚¬ìœ (ìˆë‹¤ë©´) ì¶”ì¶œ
        prompt_feedback = getattr(resp, "prompt_feedback", None)
        if prompt_feedback is not None:
            # SDK ë²„ì „ì— ë”°ë¼ ì†ì„±ëª…ì´ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ ë‘˜ ë‹¤ ì‹œë„
            out["block_reason"] = (
                getattr(prompt_feedback, "block_reason", None)
                or getattr(prompt_feedback, "block_reason_message", None)
            )

        candidates = getattr(resp, "candidates", []) or []
        if not candidates:
            return out

        c0 = candidates[0]

        # finish_reason (enum or int â†’ strë¡œ ì •ê·œí™”)
        finish_reason = getattr(c0, "finish_reason", None)
        out["finish_reason"] = getattr(finish_reason, "name", None) or str(finish_reason) if finish_reason is not None else None

        # SAFETY ì°¨ë‹¨ ì—¬ë¶€
        if out["finish_reason"] and str(out["finish_reason"]).upper() == "SAFETY":
            out["blocked"] = True

        # safety_ratings ê·¸ëŒ€ë¡œ ë³´ê´€ (íƒ€ì… Any)
        out["safety_ratings"] = getattr(c0, "safety_ratings", None)

        # ë³¸ë¬¸ partsì—ì„œ í…ìŠ¤íŠ¸ ì¡°ë¦½
        content = getattr(c0, "content", None)
        parts = getattr(content, "parts", None) if content is not None else None
        if parts:
            out["has_parts"] = True
            pieces: list[str] = []
            for p in parts:
                t = getattr(p, "text", None)
                if isinstance(t, str) and t:   # â† íƒ€ì… ì²´ì»¤ OK
                    pieces.append(t)
            if pieces:
                joined = "".join(pieces).strip()
                if joined:
                    out["text"] = joined

        return out

    except Exception as exc:
        # íŒŒì‹± ì¤‘ ì˜ˆì™¸ëŠ” ë¡œê¹…ë§Œ í•˜ê³ , out ê¸°ë³¸ê°’ ë°˜í™˜
        print(f"âš ï¸ ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜(íŒŒíŠ¸ ì¶”ì¶œ): {type(exc).__name__}: {exc}")
        return out


def _low_temp_json_reprompt(model_name: str, base_prompt: str, request_options: RequestOptions) -> str | None:
    """
    is_json=Trueì¸ë° partsê°€ ë¹„ì—ˆì„ ë•Œ, ì €ì˜¨Â·ë‹¨í˜¸í•œ í˜•ì‹ ì§€ì‹œë¡œ 1íšŒ ì¬í”„ë¡¬í”„íŠ¸.
    """
    try:
        model = genai.GenerativeModel(model_name)
        strict_prompt = (
            "You must return ONLY valid JSON.\n"
            "Do NOT include any explanations, code fences, or markdown.\n"
            "Return a JSON array or object as requested.\n\n"
            f"{base_prompt}"
        )
        resp = model.generate_content(
            [{"role": "user", "parts": [{"text": strict_prompt}]}],
            generation_config=genai.types.GenerationConfig(
                temperature=0.2,
                response_mime_type="application/json",
                candidate_count=1,
            ),
            request_options=request_options,
        )
        ex = _extract_text_from_parts(resp)
        print(f"   â””â”€ ì €ì˜¨ ì¬í”„ë¡¬í”„íŠ¸ ê²°ê³¼: finish_reason={ex['finish_reason']} | has_parts={ex['has_parts']}")
        if ex["blocked"]:
            print("   â””â”€ ì €ì˜¨ ì¬í”„ë¡¬í”„íŠ¸ë„ SAFETY ì°¨ë‹¨")
            return None
        return ex["text"] if ex["text"] else None
    except Exception as exc:
        print(f"   â””â”€ ì €ì˜¨ ì¬í”„ë¡¬í”„íŠ¸ ì˜ˆì™¸: {type(exc).__name__}: {exc}")
        return None


def _is_retryable_exception(exc: Exception) -> bool:
    retryable_types = (
        getattr(gax, "DeadlineExceeded", tuple()),
        getattr(gax, "ServiceUnavailable", tuple()),
        getattr(gax, "ResourceExhausted", tuple()),  # 429
        getattr(gax, "InternalServerError", tuple()),
    )
    if isinstance(exc, retryable_types):
        return True
    msg = str(exc).lower()
    retry_keywords = [
        "deadline exceeded", "service unavailable", "temporarily unavailable",
        "connection reset", "connection aborted", "timed out", "timeout",
        "rate limit", "429", "unavailable", "try again"
    ]
    return any(k in msg for k in retry_keywords)

def _backoff(attempt: int, base: float = 1.0, cap: float = 20.0) -> float:
    wait = min(cap, base * (2 ** attempt))
    wait *= (0.5 + random.random())  # 0.5~1.5 ì§€í„°
    return wait


def sleep_with_exact(seconds: float, label: Optional[str] = None) -> None:
    """monotonic ê¸°ì¤€ìœ¼ë¡œ ì •í™•íˆ secondsë§Œí¼ ëŒ€ê¸°. 1ì´ˆ ë‹¨ìœ„ ì¹´ìš´íŠ¸ë‹¤ìš´ ë¡œê·¸."""
    if seconds <= 0:
        return
    start = time.monotonic()
    end = start + seconds
    if label:
        print(f"â³ {seconds:.1f}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„ | {label}", flush=True)
    else:
        print(f"â³ {seconds:.1f}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„", flush=True)

    # 1ì´ˆ ê°„ê²© ì¹´ìš´íŠ¸ë‹¤ìš´(ë„ˆë¬´ ì‹œë„ëŸ½ë‹¤ë©´ ì£¼ì„ì²˜ë¦¬ ê°€ëŠ¥)
    last_print = int(seconds)
    while True:
        now = time.monotonic()
        remaining = end - now
        if remaining <= 0:
            break
        rem_int = int(remaining)
        if rem_int < last_print:  # ì´ˆê°€ ë°”ë€” ë•Œë§Œ ì°ìŒ
            print(f"   â€¦ ë‚¨ì€ ëŒ€ê¸°: {rem_int}s", flush=True)
            last_print = rem_int
        # 100~200ms ë‹¨ìœ„ë¡œ ì§§ê²Œ ì”ë‹¤ (ì •í™•ë„â†‘)
        time.sleep(min(0.2, remaining))
    # ì‹¤ì œ ê²½ê³¼ í™•ì¸
    elapsed = time.monotonic() - start
    print(f"â±ï¸ ì‹¤ì œ ëŒ€ê¸°: {elapsed:.2f}s", flush=True)



def _make_style_guideline(filename: str) -> str:
    if filename == "thumb":
        return "- ìŠ¤íƒ€ì¼: ë¯¸ë‹ˆë©€ë¦¬ì¦˜, í”Œë« ë””ìì¸, ë²¡í„° ì•„íŠ¸\n- êµ¬ì„±: ì£¼ì œë¥¼ ìƒì§•í•˜ëŠ” ì•„ì´ì½˜/ì˜¤ë¸Œì íŠ¸ ì¤‘ì‹¬\n- í…ìŠ¤íŠ¸/ë¡œê³  ê¸ˆì§€"
    elif filename == "scene":
        return "- ìŠ¤íƒ€ì¼: ê·¹ì‚¬ì‹¤ì , ê³ í’ˆì§ˆ ì‚¬ì§„\n- êµ¬ì„±: ì£¼ì œì˜ ê°œë…/ìƒí™©ì„ ì€ìœ ì ìœ¼ë¡œ ë¬˜ì‚¬\n- ì¡°ëª…/ë°°ê²½: ìì—°ê´‘ ë˜ëŠ” cinematic lighting, ë°°ê²½ ì‹¬ë„(depth of field)\n- í…ìŠ¤íŠ¸/ë¡œê³  ê¸ˆì§€"
    return "- ìŠ¤íƒ€ì¼: ê³ í’ˆì§ˆì˜ ìƒì§• ì‚¬ì§„\n- í…ìŠ¤íŠ¸/ë¡œê³  ê¸ˆì§€"

def _build_meta_prompt(article: str, description: str, style_guideline: str) -> str:
    # ê¸€ ìš”ì•½ì€ ë„ˆë¬´ ê¸¸ë©´ ëª¨ë¸ì´ ë¹ˆ partsë¥¼ ë°˜í™˜í•˜ëŠ” ê²½ìš°ê°€ ìˆì–´ 500ì ì œí•œ
    summary = (article or "")[:500]
    return (
        "[ì—­í• ] ë‹¹ì‹ ì€ ì¶”ìƒ ê°œë…ì„ ì‹œê°í™”í•˜ëŠ” AI ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ì´ì ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤.\n"
        "[ì§€ì‹œ] ì•„ë˜ 'ê¸€ ìš”ì•½'ê³¼ 'ì£¼ì œ'ë¥¼ ì°¸ê³ í•˜ì—¬ Stable Diffusionìš© 'image_prompt'ì™€ ë¸”ë¡œê·¸ 'caption'ì„ ìƒì„±í•˜ì„¸ìš”.\n"
        "[ê·œì¹™]\n"
        "- ì¸ë¬¼ë³´ë‹¤ ì£¼ì œë¥¼ ì˜ ìƒì§•í•˜ëŠ” ì‚¬ë¬¼/í’ê²½/ì¶”ìƒ ì´ë¯¸ì§€ ìœ„ì£¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ í‘œí˜„\n"
        "- í”„ë¡¬í”„íŠ¸ì—ëŠ” í…ìŠ¤íŠ¸(ê¸€ì)ë‚˜ ë¡œê³ , ì›Œí„°ë§ˆí¬ë¥¼ í¬í•¨í•˜ì§€ ë§ ê²ƒ\n"
        f"[ìŠ¤íƒ€ì¼ ê°€ì´ë“œ]\n{style_guideline}\n"
        "[ì¶œë ¥ í˜•ì‹]\n"
        "- ë°˜ë“œì‹œ {\"image_prompt\": \"...\", \"caption\": \"...\"} í˜•ì‹ì˜ ìˆœìˆ˜ JSONë¡œë§Œ ì‘ë‹µ\n"
        f"[ê¸€ ìš”ì•½] {summary}\n"
        f"[ì£¼ì œ] {description}\n"
    )

def _fallback_prompt(description: str) -> Tuple[str, str]:
    # ëŒ€ì²´ í”„ë¡¬í”„íŠ¸(ì§§ê³  ì•ˆì „). í…ìŠ¤íŠ¸/ë¡œê³ /ì›Œí„°ë§ˆí¬ ê¸ˆì§€ í¬í•¨.
    desc = (description or "").strip()
    short_prompt = (
        f"{desc}, symbolic representation, photorealistic or abstract scene, "
        "no text, no logo, no watermark, clean background, well-composed"
    )
    caption = _clean_caption(desc or "ê´€ë ¨ ì£¼ì œ ì´ë¯¸ì§€")
    return short_prompt, caption



def _clean_caption(text: str, max_len: int = 140) -> str:
    # ì¤„ë°”ê¿ˆ/ê³µë°± ì •ë¦¬, ë”°ì˜´í‘œ ê³¼ë‹¤ ì œê±°, ê¸¸ì´ ì œí•œ
    s = re.sub(r"\s+", " ", text or "").strip()
    s = s.strip('"\'')

    if len(s) > max_len:
        s = s[:max_len - 1].rstrip() + "â€¦"
        s = s[:max_len - 3].rstrip() + "..."
    return s

def _sleep_exact(seconds: float, label: Optional[str] = None) -> None:
    if seconds <= 0:
        return
    start = time.monotonic()
    end = start + seconds
    if label:
        print(f"â³ {seconds:.1f}ì´ˆ ëŒ€ê¸° | {label}", flush=True)
    else:
        print(f"â³ {seconds:.1f}ì´ˆ ëŒ€ê¸°", flush=True)
    while True:
        now = time.monotonic()
        if now >= end:
            break
        time.sleep(min(0.2, end - now))
    elapsed = time.monotonic() - start
    print(f"â±ï¸ ì‹¤ì œ ëŒ€ê¸°: {elapsed:.2f}s", flush=True)

def build_images_to_blog(
    article: str,
    filename: str,
    description: str,
    slug: str,
    *,
    workflow_path: str | None = None,
    width: int | None = None,
    height: int = 512,
    steps: int = 28,
):
    import json
    import time
    from io import BytesIO
    from pathlib import Path
    from PIL import Image

    # 1) í”„ë¡¬í”„íŠ¸/ìº¡ì…˜ ì¤€ë¹„ ----------------------------------------------
    try:
        print(f"â–¶ [ComfyBlog] Geminië¡œ [{filename}] ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸/ìº¡ì…˜ ìƒì„± ìš”ì²­.", flush=True)

        style_guideline = _make_style_guideline(filename)
        meta_prompt = _build_meta_prompt(article, description, style_guideline)

        response_text = call_gemini(meta_prompt, temperature=0.6, is_json=True)

        try:
            if response_text in ("SAFETY_BLOCKED", "API_ERROR") or not response_text:
                raise ValueError(f"Gemini ì‹¤íŒ¨: {response_text}")

            parsed = json.loads(response_text)
            short_prompt = (parsed.get("image_prompt") or "").strip()
            image_caption = (parsed.get("caption") or "").strip()
            if not short_prompt or not image_caption:
                raise ValueError("JSONì— image_prompt/caption ëˆ„ë½")
        except Exception as exc:
            print(f"âš ï¸ [ComfyBlog] AI í”„ë¡¬í”„íŠ¸/ìº¡ì…˜ ìƒì„± ì‹¤íŒ¨: {exc} â†’ ëŒ€ì²´ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©", flush=True)
            short_prompt, image_caption = _fallback_prompt(description)

        negative = (
            "(text, logo, watermark:1.5), (deformed, distorted, disfigured:1.2), poorly drawn, bad anatomy, "
            "blurry, lowres, nsfw, nude, extra fingers, mutated hands"
        )
        base_quality = "masterpiece, best quality, ultra-detailed, high resolution"
        final_prompt = f"{base_quality}, {short_prompt}".strip()
        if len(final_prompt) > 480:
            final_prompt = final_prompt[:480]

    except Exception as e_prompt:
        print(f"âŒ [ComfyBlog] í”„ë¡¬í”„íŠ¸ ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜: {type(e_prompt).__name__}: {e_prompt}", flush=True)
        return None, None

    # 2) ComfyUI ì›Œí¬í”Œë¡œ ë¡œë“œ ----------------------------------------------
    try:
        try:
            comfy_host = getattr(settings, "COMFY_HOST", "http://127.0.0.1:8188")
            jsons_dir = getattr(settings, "JSONS_DIR", None)
        except Exception:
            comfy_host = "http://127.0.0.1:8188"
            jsons_dir = None

        base_url = str(comfy_host).rstrip("/")

        # ì›Œí¬í”Œë¡œìš° ì„ íƒ ë¡œì§: ì´ì œë¶€í„°ëŠ” Z-Image-lora.jsonë§Œ ì‚¬ìš©
        if workflow_path is not None:
            # í˜¸ì¶œí•˜ëŠ” ìª½ì—ì„œ ì§ì ‘ ê²½ë¡œë¥¼ ë„˜ê²¨ì¤€ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
            wf_path = Path(workflow_path)
        else:
            wf_name = "Z-Image-lora.json"
            if jsons_dir:
                wf_path = Path(jsons_dir) / wf_name
            else:
                wf_path = Path(wf_name)

        if not wf_path.exists():
            raise FileNotFoundError(
                f"ComfyUI ì›Œí¬í”Œë¡œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {wf_path}"
            )

        with open(wf_path, "r", encoding="utf-8") as f:
            graph = json.load(f)

        # â˜…â˜…â˜… ë¸”ë¡œê·¸ì—ì„œëŠ” ì•ˆ ì“¸ ë…¸ë“œ ë„ê¸° â˜…â˜…â˜…
        def _disable_blog_nodes(g: dict) -> None:
            # ì—…ìŠ¤ì¼€ì¼, ë¹„ë””ì˜¤, ë¦¬ì•¡í„° ê³„ì—´ ë„ê¸°
            UPSCALE = {
                "ImageUpscaleWithModel",
                "ImageScale",
                "LatentUpscale",
                "ImageResize",
            }
            VIDEO = {
                "VHS_VideoCombine",
                "VHS_VideoSave",
                "VHS_VideoLoader",
                "VHS_VideoPreview",
                "VideoHelperSuite",
            }
            FACE = {
                "ReActorFaceSwap",
                "ReActorLoader",
            }

            for node_id, node_data in g.items():
                class_type = str(node_data.get("class_type") or "")
                if class_type in UPSCALE or class_type in VIDEO or class_type in FACE:
                    node_data.setdefault("inputs", {})
                    node_data["inputs"]["enabled"] = False

        _disable_blog_nodes(graph)

        # 3) ë¸”ë¡œê·¸ìš©ìœ¼ë¡œ prompt / size / steps ì£¼ì… -------------------------
        def _set_input(g: dict, nid: str, key: str, val):
            g[str(nid)].setdefault("inputs", {})[key] = val

        target_w = width or (768 if filename == "scene" else 640)
        target_h = height

        for node_id, node in graph.items():
            ctype = str(node.get("class_type") or "")
            inputs_map = node.get("inputs", {})

            if ctype.startswith("Empty") and "width" in inputs_map:
                _set_input(graph, node_id, "width", int(target_w))
                _set_input(graph, node_id, "height", int(target_h))

            if ctype.lower().startswith("cliptextencode") or "text" in inputs_map:
                label = str(node.get("label") or "").lower()
                if "neg" in label or "negative" in label:
                    _set_input(graph, node_id, "text", negative)
                else:
                    _set_input(graph, node_id, "text", final_prompt)

            if ctype == "KSampler":
                _set_input(graph, node_id, "steps", int(steps))

        # 4) /prompt ì œì¶œ ----------------------------------------------------
        payload = {
            "prompt": graph,
            "extra_pnginfo": {
                "workflow": graph
            },
        }

        resp = requests.post(base_url + "/prompt", json=payload, timeout=15)
        resp.raise_for_status()
        prompt_id = resp.json().get("prompt_id")
        if not prompt_id:
            raise RuntimeError("ComfyUIê°€ prompt_idë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # 5) /history ì—ì„œ ì´ë¯¸ì§€ ì°¾ê¸° ---------------------------------------
        t0 = time.time()
        img_bytes: bytes | None = None
        while time.time() - t0 < 300:
            h = requests.get(base_url + f"/history/{prompt_id}", timeout=10)
            if h.status_code == 200:
                hjson = h.json()
                outputs = hjson.get(prompt_id, {}).get("outputs") or {}
                for _, out_val in outputs.items():
                    imgs = out_val.get("images") or []
                    if imgs:
                        # ì´ë¯¸ì§€ì¸ ê²ƒë¶€í„° ê³ ë¥¸ë‹¤
                        def _is_image_name(name: str) -> bool:
                            name = name.lower()
                            return name.endswith(".png") or name.endswith(".jpg") or name.endswith(".jpeg") or name.endswith(".webp")

                        chosen = None
                        for cand in imgs:
                            if _is_image_name(cand.get("filename", "")):
                                chosen = cand
                                break
                        if not chosen:
                            # ì „ë¶€ ë™ì˜ìƒì´ë©´ ê·¸ëƒ¥ ë§ˆì§€ë§‰ ê±¸ë¡œ
                            chosen = imgs[-1]

                        fname = chosen.get("filename")
                        subfolder = chosen.get("subfolder") or ""

                        # ë¨¼ì € outputìœ¼ë¡œ
                        params = {"filename": fname, "type": "output"}
                        if subfolder:
                            params["subfolder"] = subfolder

                        try:
                            view = requests.get(base_url + "/view", params=params, timeout=30)
                            view.raise_for_status()
                            img_bytes = view.content
                        except requests.HTTPError:
                            # ì•ˆ ë˜ë©´ tempë¡œ
                            params["type"] = "temp"
                            view = requests.get(base_url + "/view", params=params, timeout=30)
                            view.raise_for_status()
                            img_bytes = view.content

                        break
            if img_bytes:
                break
            time.sleep(1.5)

        if not img_bytes:
            raise RuntimeError("ComfyUIì—ì„œ ì´ë¯¸ì§€ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        # 6) ì›Œë“œí”„ë ˆìŠ¤ìš© media ë¡œ ë³€í™˜ (SDì™€ ë¹„ìŠ·í•˜ê²Œ ë¦¬ì‚¬ì´ì¦ˆ) ------------
        img = Image.open(BytesIO(img_bytes)).convert("RGB")
        target_w = 768 if filename == "scene" else 640
        target_h = 512
        resample_lanczos = getattr(
            getattr(Image, "Resampling", Image),  # 1ìˆœìœ„: Image.Resampling
            "LANCZOS",  # 2ìˆœìœ„: ê±°ê¸°ì„œ LANCZOS
            1,  # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ 1 (lanczos) ìˆ«ìê°’
        )

        img = img.resize((target_w, target_h), resample_lanczos)

        buf = BytesIO()
        img.save(buf, format="WEBP", quality=85)
        webp_bytes = buf.getvalue()

        image_file = BytesIO(webp_bytes)
        image_file.name = f"{slug}_{filename}.webp"
        image_file.seek(0)

        safe_caption = _clean_caption(image_caption)

        media = {
            "name": image_file.name,
            "type": "image/webp",
            "caption": safe_caption,
            "description": (description or "").strip(),
            "bits": xmlrpc_client.Binary(image_file.read()),
        }
        return media, safe_caption

    except Exception as e_img:
        print(f"âš ï¸ [ComfyBlog] ì´ë¯¸ì§€ ìƒì„±/ë³€í™˜ ì¤‘ ì˜ˆì™¸: {type(e_img).__name__}: {e_img}", flush=True)
        return None, None





