# -*- coding: utf-8 -*-
from __future__ import annotations
import json
import re

from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Callable, Optional
import json
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
ISSUE_LIST_ROOT = Path(r"C:\my_games\shorts_make\issue_list")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì™¸ë¶€ ì†ŒìŠ¤ ëª¨ë“ˆ ì„í¬íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ìœ íŠœë¸Œ / Reddit / ì¿ íŒ¡ ìŠ¤í…
try:
    from app.shopping_sources import (
        collect_youtube_shopping_trends,
        collect_reddit_shopping_trends,
        collect_coupang_best_and_rising,
    )
except Exception:
    # ë¬¸ì œê°€ ë‚˜ë”ë¼ë„ ì „ì²´ê°€ ì£½ì§€ ì•Šë„ë¡ ì•ˆì „í•œ ë”ë¯¸ í•¨ìˆ˜ ì œê³µ
    def collect_youtube_shopping_trends(max_items: int = 50) -> List[Dict[str, Any]]:
        return []

    def collect_reddit_shopping_trends(max_items: int = 50) -> List[Dict[str, Any]]:
        return []

    def collect_coupang_best_and_rising(max_items: int = 50) -> List[Dict[str, Any]]:
        return []

# ë„¤ì´ë²„ ì¶”ê°€ ì¹´í…Œê³ ë¦¬ + ì—°í•©ë‰´ìŠ¤ íŠ¸ë Œë“œ
try:
    from app.blog_trend_search_page import (
        get_naver_news_multi_category_topics,
        get_yonhap_news_trend_topics,
    )
except Exception:
    # blog_trend_search_page ë¥¼ ëª» ë¶ˆëŸ¬ì˜¤ë”ë¼ë„ ì „ì²´ê°€ ì£½ì§€ ì•Šê²Œ ë”ë¯¸ í•¨ìˆ˜
    def get_naver_news_multi_category_topics(max_items_per_category: int = 30) -> List[Dict[str, Any]]:
        return []

    def get_yonhap_news_trend_topics(max_items_per_category: int = 30) -> List[Dict[str, Any]]:
        return []


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê³µìš© ì €ì¥ ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _save_issue_list_json(
    topics: List[Dict[str, Any]],
    *,
    suffix: str = "",
    on_progress: Optional[Callable[[Dict[str, Any]], None]] = None,
) -> Path:
    """issue_list/YYYYMMDD/HHMMSS{suffix}.json ì €ì¥.

    - suffix ì˜ˆ: "_a", "_b" (ì„ í–‰ ì–¸ë”ìŠ¤ì½”ì–´ í¬í•¨ ê¶Œì¥)
    """
    now = datetime.now()
    date_dir = ISSUE_LIST_ROOT / now.strftime("%Y%m%d")
    date_dir.mkdir(parents=True, exist_ok=True)

    file_path = date_dir / f"{now.strftime('%H%M%S')}{suffix}.json"
    with file_path.open("w", encoding="utf-8") as f:
        json.dump(topics, f, ensure_ascii=False, indent=2)

    msg = f"ì´ìŠˆ ë¦¬ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: {file_path}"
    if callable(on_progress):
        try:
            on_progress({"stage": "save", "msg": msg})
        except Exception:
            pass

    print(f"ğŸ’¾ {msg}")
    return file_path


def _coerce_topic_schema(item: Dict[str, Any]) -> Dict[str, Any]:
    """ìµœì†Œ ìŠ¤í‚¤ë§ˆ ì •ê·œí™”.

    ìµœì¢… ì €ì¥ í¬ë§·(ìš”êµ¬ì‚¬í•­):
      {
        "source": "...",
        "title": "...",
        "rank": 10,
        "url": "https://..." | None
      }

    - extra í•„ë“œëŠ” ìˆì–´ë„ ë¬´ë°©í•˜ë¯€ë¡œ ìœ ì§€í•œë‹¤.
    """
    src = (item.get("source") or "").strip() or "unknown"
    title = (item.get("title") or "").strip()
    rank = item.get("rank", 0)
    try:
        rank = int(rank) if rank is not None else 0
    except Exception:
        rank = 0

    url = item.get("url")
    if url is not None:
        url = str(url).strip() or None

    out: Dict[str, Any] = {
        "source": src,
        "title": title,
        "rank": rank,
        "url": url,
    }

    # extraëŠ” ìœ ì§€(ìˆë‹¤ë©´)
    if "extra" in item:
        out["extra"] = item.get("extra")

    return out


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Selenium (ë„¤ì´ë²„ ë‰´ìŠ¤ ê¸°ë³¸ ë­í‚¹/ê²½ì œ ìš©)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _create_driver():
    """
    Selenium Chrome ë“œë¼ì´ë²„ ìƒì„± (headless).
    - ì´ ëª¨ë“ˆ ì•ˆì—ì„œë§Œ ì‚¬ìš©.
    """


    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument(
        "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/120.0 Safari/537.36"
    )

    driver = webdriver.Chrome(
        service=Service(ChromeDriverManager().install()),
        options=options,
    )
    return driver


def _scrape_naver_news_titles(driver, url: str, limit: int = 50) -> List[str]:
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ ë­í‚¹/ê²½ì œ ì„¹ì…˜ ë“±ì—ì„œ ê¸°ì‚¬ ì œëª© ì¶”ì¶œ.
    - ì—¬ëŸ¬ CSS í›„ë³´ë¥¼ ëŒë©´ì„œ ìµœëŒ€í•œ í…ìŠ¤íŠ¸ë¥¼ ë½‘ëŠ”ë‹¤.
    """


    driver.get(url)

    try:
        WebDriverWait(driver, 15).until(
            EC.presence_of_all_elements_located((By.CSS_SELECTOR, "body"))
        )
    except Exception:
        pass

    html = driver.page_source
    soup = BeautifulSoup(html, "html.parser")

    titles_raw: List[str] = []

    # 1ì°¨: ì¼ë°˜ ê¸°ì‚¬ ë§í¬ íŒ¨í„´
    for a in soup.select("a[href*='/read?']"):
        text = (a.get_text() or "").strip()
        if not text:
            continue
        if len(text) < 8 or len(text) > 80:
            continue
        titles_raw.append(text)

    # 2ì°¨: ë­í‚¹/ë¦¬ìŠ¤íŠ¸ ì „ìš© í´ë˜ìŠ¤ í›„ë³´ë“¤ (ë„¤ì´ë²„ êµ¬ì¡° ë³€ê²½ ëŒ€ë¹„)
    css_candidates = [
        "a.rankingnews_link",                # ë­í‚¹ë‰´ìŠ¤ ì œëª©
        "ol.ranking_list a",                 # ë­í‚¹ ë¦¬ìŠ¤íŠ¸
        "div.list_body a",                   # ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸
        "a[class*='cluster_text_headline']", # í´ëŸ¬ìŠ¤í„° í—¤ë“œë¼ì¸
        "a[class*='list_title']",            # ë¦¬ìŠ¤íŠ¸ ì œëª©
        "a[class*='sa_text_title']",         # ê²€ìƒ‰/ì„¹ì…˜ ì œëª©
    ]
    for css in css_candidates:
        for a in soup.select(css):
            text = (a.get_text() or "").strip()
            if not text:
                continue
            if len(text) < 8 or len(text) > 80:
                continue
            titles_raw.append(text)

    # ì¤‘ë³µ ì œê±° + limit
    seen = set()
    titles: List[str] = []
    for t in titles_raw:
        if t in seen:
            continue
        seen.add(t)
        titles.append(t)
        if len(titles) >= limit:
            break

    print(f"âœ… [NAVER NEWS] {url} ì œëª© {len(titles)}ê°œ ì¶”ì¶œ")
    return titles


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) ë„¤ì´ë²„ ì „ìš© (ë­í‚¹ + ê²½ì œ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def collect_raw_topics_for_shopping_naver(
    on_progress: Optional[Callable[[Dict[str, Any]], None]] = None,
) -> List[Dict[str, Any]]:
    """
    [1ë‹¨ê³„ ì „ìš©]
    - ë„¤ì´ë²„ ë‰´ìŠ¤ ë­í‚¹
    - ë„¤ì´ë²„ ê²½ì œ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸

    ë§Œ ëª¨ì•„ì„œ "ì‡¼í•‘/ì´ìŠˆìš© ì›ì‹œ í† í”½ í’€"ì„ ë§Œë“ ë‹¤.
    (AI íŒë‹¨ì€ ì—¬ê¸°ì„œ í•˜ì§€ ì•ŠìŒ)
    """

    def _prog(msg: str, stage: str = "info"):
        if callable(on_progress):
            try:
                on_progress({"stage": stage, "msg": msg})
            except Exception:
                pass

    topics: List[Dict[str, Any]] = []
    driver = None

    rank_titles: List[str] = []
    econ_titles: List[str] = []

    try:
        _prog("ë„¤ì´ë²„ í¬ë¡¬ ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì¤‘...", stage="init")
        driver = _create_driver()

        # 1) ë„¤ì´ë²„ ë‰´ìŠ¤ ë­í‚¹
        _prog("ë„¤ì´ë²„ ë‰´ìŠ¤ ë­í‚¹ ì œëª© ìˆ˜ì§‘ ì‹œì‘", stage="news_rank")
        rank_url = "https://news.naver.com/main/ranking/popularDay.naver?mid=etc&sid1=111"
        rank_titles = _scrape_naver_news_titles(driver, rank_url, limit=50)
        for idx, title in enumerate(rank_titles, start=1):
            topics.append(
                {
                    "source": "naver_news_rank",
                    "title": title,
                    "rank": idx,
                    "url": None,
                }
            )

        # 2) ë„¤ì´ë²„ ê²½ì œ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
        _prog("ë„¤ì´ë²„ ê²½ì œ ë‰´ìŠ¤ ì œëª© ìˆ˜ì§‘ ì‹œì‘", stage="news_econ")
        econ_url = "https://news.naver.com/main/list.naver?mode=LSD&mid=sec&sid1=101"
        econ_titles = _scrape_naver_news_titles(driver, econ_url, limit=50)
        for idx, title in enumerate(econ_titles, start=1):
            topics.append(
                {
                    "source": "naver_news_economy",
                    "title": title,
                    "rank": idx,
                    "url": None,
                }
            )

    except Exception as e:
        _prog(f"ë„¤ì´ë²„ ì´ìŠˆ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}", stage="error")
        print(f"âš  ë„¤ì´ë²„ ì´ìŠˆ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

    finally:
        if driver is not None:
            try:
                driver.quit()
            except Exception:
                pass

    total = len(topics)
    msg_detail = (
        f"ë„¤ì´ë²„ ë‰´ìŠ¤ ë­í‚¹ {len(rank_titles)}ê°œ, "
        f"ê²½ì œ ë‰´ìŠ¤ {len(econ_titles)}ê°œ, ì´ {total}ê°œ ìˆ˜ì§‘ ì™„ë£Œ"
    )
    _prog(msg_detail, stage="done")
    print(f"ğŸ§© {msg_detail}")
    return topics


def save_issue_list_for_shopping_naver(
    on_progress: Optional[Callable[[Dict[str, Any]], None]] = None,
) -> Path:
    """
    ë„¤ì´ë²„ ê¸°ë°˜ ì‡¼í•‘/ì´ìŠˆ í† í”½ë“¤ì„ ëª¨ì•„ì„œ
    C:\\my_games\\shorts_make\\issue_list\\YYYYMMDD\\HHMMSS.json ìœ¼ë¡œ ì €ì¥í•œë‹¤.
    """
    topics = collect_raw_topics_for_shopping_naver(on_progress=on_progress)

    now = datetime.now()
    date_dir = ISSUE_LIST_ROOT / now.strftime("%Y%m%d")
    date_dir.mkdir(parents=True, exist_ok=True)

    file_path = date_dir / f"{now.strftime('%H%M%S')}_a.json"


    with file_path.open("w", encoding="utf-8") as f:
        json.dump(topics, f, ensure_ascii=False, indent=2)

    msg = f"ë„¤ì´ë²„ ì´ìŠˆ ë¦¬ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: {file_path}"
    if callable(on_progress):
        try:
            on_progress({"stage": "save", "msg": msg})
        except Exception:
            pass

    print(f"ğŸ’¾ {msg}")
    return file_path


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) ì „ì²´ ì‡¼í•‘ ì´ìŠˆ (ë„¤ì´ë²„ + ë„¤ì´ë²„ì¶”ê°€ + ì¿ íŒ¡ìŠ¤í… + ìœ íŠœë¸Œ + Reddit + ì—°í•©ë‰´ìŠ¤)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def collect_raw_topics_for_shopping_all(
    on_progress: Optional[Callable[[Dict[str, Any]], None]] = None,
) -> List[Dict[str, Any]]:
    """
    [1ë‹¨ê³„ í™•ì¥ ë²„ì „]

    - ë„¤ì´ë²„ ì´ìŠˆ(ë‰´ìŠ¤ ë­í‚¹ + ê²½ì œ)
    - ë„¤ì´ë²„ ì¶”ê°€ ì¹´í…Œê³ ë¦¬(ì‚¬íšŒ/ìƒí™œ/IT)  â† blog_trend_search_page.get_naver_news_multi_category_topics
    - ì¿ íŒ¡ BEST/ê¸‰ìƒìŠ¹ (í˜„ì¬ëŠ” ìŠ¤í…: í•­ìƒ ë¹ˆ ë¦¬ìŠ¤íŠ¸)
    - ìœ íŠœë¸Œ ì‡¼í•‘/ë¦¬ë·°/ì‡¼ì¸  íŠ¸ë Œë“œ
    - í•´ì™¸ ì‡¼í•‘ íŠ¸ë Œë“œ(Reddit)
    - ì—°í•©ë‰´ìŠ¤ íŠ¸ë Œë“œ/í•«/ìƒí™œ/ê²½ì œ/IT

    ë¥¼ ì „ë¶€ í•©ì³ì„œ "ì‡¼í•‘/ì´ìŠˆìš© ì›ì‹œ í† í”½ í’€"ì„ ë§Œë“ ë‹¤.
    (AI íŒë‹¨/í•„í„°ë§ì€ ì—¬ê¸°ì„œ í•˜ì§€ ì•ŠìŒ)
    """

    def _prog(msg: str, stage: str = "info") -> None:
        if callable(on_progress):
            try:
                on_progress({"stage": stage, "msg": msg})
            except Exception:
                pass

    topics: List[Dict[str, Any]] = []

    naver_topics: List[Dict[str, Any]] = []
    naver_extra_topics: List[Dict[str, Any]] = []
    coupang_topics: List[Dict[str, Any]] = []
    yt_topics: List[Dict[str, Any]] = []
    rd_topics: List[Dict[str, Any]] = []
    yonhap_topics: List[Dict[str, Any]] = []

    # 1) ë„¤ì´ë²„ ê¸°ë³¸(ë­í‚¹/ê²½ì œ)
    try:
        _prog("ë„¤ì´ë²„ ì´ìŠˆ(ë‰´ìŠ¤ ë­í‚¹/ê²½ì œ) ìˆ˜ì§‘ ì‹œì‘", stage="naver")
        naver_topics = collect_raw_topics_for_shopping_naver(on_progress=on_progress)
        topics.extend(naver_topics)
    except Exception as e:
        _prog(f"ë„¤ì´ë²„ ì´ìŠˆ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}", stage="error")
        print(f"âš  ë„¤ì´ë²„ ì´ìŠˆ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

    # 1-ì¶”ê°€) ë„¤ì´ë²„ ì¶”ê°€ ì¹´í…Œê³ ë¦¬(ì‚¬íšŒ/ìƒí™œ/IT) â€“ blog_trend_search_page ì‚¬ìš©
    try:
        _prog("ë„¤ì´ë²„ ì¶”ê°€ ì¹´í…Œê³ ë¦¬(ì‚¬íšŒ/ìƒí™œ/IT) ìˆ˜ì§‘ ì‹œì‘", stage="naver_extra")
        naver_extra_topics = get_naver_news_multi_category_topics(max_items_per_category=30)
        topics.extend(naver_extra_topics)
        _prog(f"ë„¤ì´ë²„ ì¶”ê°€ ì¹´í…Œê³ ë¦¬ í† í”½ {len(naver_extra_topics)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ", stage="naver_extra")
    except Exception as e:
        _prog(f"ë„¤ì´ë²„ ì¶”ê°€ ì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}", stage="error")
        print(f"âš  ë„¤ì´ë²„ ì¶”ê°€ ì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

    # 2) ì¿ íŒ¡ BEST/ê¸‰ìƒìŠ¹ (í˜„ì¬ëŠ” ìŠ¤í…: í•­ìƒ []).
    try:
        _prog("ì¿ íŒ¡ BEST/ê¸‰ìƒìŠ¹(ìŠ¤í…) ìˆ˜ì§‘ ì‹œì‘", stage="coupang")
        coupang_topics = collect_coupang_best_and_rising(max_items=50)
        topics.extend(coupang_topics)
        _prog(f"ì¿ íŒ¡ íŠ¸ë Œë“œ í† í”½ {len(coupang_topics)}ê°œ ìˆ˜ì§‘ (í˜„ì¬ ìŠ¤í…)", stage="coupang")
    except Exception as e:
        _prog(f"ì¿ íŒ¡ íŠ¸ë Œë“œ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}", stage="error")
        print(f"âš  ì¿ íŒ¡ íŠ¸ë Œë“œ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

    # 3) ìœ íŠœë¸Œ ì‡¼í•‘/ì‡¼ì¸  íŠ¸ë Œë“œ
    try:
        _prog("ìœ íŠœë¸Œ ì‡¼í•‘/ì‡¼ì¸  íŠ¸ë Œë“œ ìˆ˜ì§‘ ì‹œì‘", stage="youtube")
        yt_topics = collect_youtube_shopping_trends(max_items=50)
        topics.extend(yt_topics)
        _prog(f"ìœ íŠœë¸Œ ì‡¼í•‘/ì‡¼ì¸  í† í”½ {len(yt_topics)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ", stage="youtube")
    except Exception as e:
        _prog(f"ìœ íŠœë¸Œ ì‡¼í•‘ íŠ¸ë Œë“œ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}", stage="error")
        print(f"âš  ìœ íŠœë¸Œ ì‡¼í•‘ íŠ¸ë Œë“œ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

    # 4) í•´ì™¸ ì‡¼í•‘ íŠ¸ë Œë“œ(Reddit)
    try:
        _prog("í•´ì™¸ ì‡¼í•‘ íŠ¸ë Œë“œ(Reddit) ìˆ˜ì§‘ ì‹œì‘", stage="reddit")
        rd_topics = collect_reddit_shopping_trends(max_items=50)
        topics.extend(rd_topics)
        _prog(f"Reddit ì‡¼í•‘ í† í”½ {len(rd_topics)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ", stage="reddit")
    except Exception as e:
        _prog(f"Reddit ì‡¼í•‘ íŠ¸ë Œë“œ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}", stage="error")
        print(f"âš  Reddit ì‡¼í•‘ íŠ¸ë Œë“œ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

    # 5) ì—°í•©ë‰´ìŠ¤ íŠ¸ë Œë“œ(ì¸ê¸°/í•«/ìƒí™œ/ê²½ì œ/IT)
    try:
        _prog("ì—°í•©ë‰´ìŠ¤ íŠ¸ë Œë“œ ìˆ˜ì§‘ ì‹œì‘", stage="yonhap")
        yonhap_topics = get_yonhap_news_trend_topics(max_items_per_category=30)
        topics.extend(yonhap_topics)
        _prog(f"ì—°í•©ë‰´ìŠ¤ íŠ¸ë Œë“œ í† í”½ {len(yonhap_topics)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ", stage="yonhap")
    except Exception as e:
        _prog(f"ì—°í•©ë‰´ìŠ¤ íŠ¸ë Œë“œ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}", stage="error")
        print(f"âš  ì—°í•©ë‰´ìŠ¤ íŠ¸ë Œë“œ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

    total = len(topics)
    summary = (
        f"ë„¤ì´ë²„(ê¸°ë³¸) {len(naver_topics)}ê°œ, "
        f"ë„¤ì´ë²„(ì¶”ê°€) {len(naver_extra_topics)}ê°œ, "
        f"ì¿ íŒ¡ {len(coupang_topics)}ê°œ, "
        f"ìœ íŠœë¸Œ {len(yt_topics)}ê°œ, "
        f"Reddit {len(rd_topics)}ê°œ, "
        f"ì—°í•©ë‰´ìŠ¤ {len(yonhap_topics)}ê°œ â†’ ì´ {total}ê°œ ìˆ˜ì§‘ ì™„ë£Œ"
    )
    _prog(summary, stage="done")
    print(f"ğŸ§© {summary}")
    return topics


def save_issue_list_for_shopping_all(
    on_progress: Optional[Callable[[Dict[str, Any]], None]] = None,
) -> Path:
    """
    ë„¤ì´ë²„ + ë„¤ì´ë²„ì¶”ê°€ + ìœ íŠœë¸Œ + Reddit(+ì¿ íŒ¡ ìŠ¤í…) + ì—°í•©ë‰´ìŠ¤ ê¸°ë°˜
    ì‡¼í•‘/ì´ìŠˆ í† í”½ë“¤ì„ ëª¨ì•„ì„œ
    C:\\my_games\\shorts_make\\issue_list\\YYYYMMDD\\HHMMSS_a.json ìœ¼ë¡œ ì €ì¥í•œë‹¤.
    """
    topics = collect_raw_topics_for_shopping_all(on_progress=on_progress)

    # ê¸°ì¡´(ì›ì‹œ ì´ìŠˆ í’€)ì€ _a ë¡œ ì €ì¥
    file_path = _save_issue_list_json(topics, suffix="_a", on_progress=on_progress)
    if callable(on_progress):
        try:
            on_progress({"stage": "done", "msg": f"ì „ì²´ ì‡¼í•‘ ì´ìŠˆ ë¦¬ìŠ¤íŠ¸(_a) ì €ì¥ ì™„ë£Œ: {file_path}"})
        except Exception:
            pass
    return file_path






def _find_latest_issue_list_file(suffix: str) -> Optional[Path]:
    """issue_list/YYYYMMDD ì•„ë˜ì—ì„œ ê°€ì¥ ìµœì‹ ì˜ '*{suffix}.json' íŒŒì¼ì„ ì°¾ëŠ”ë‹¤.
    suffix ì˜ˆ: '_a', '_b'
    """
    try:
        if not ISSUE_LIST_ROOT.exists():
            return None
        date_dirs = [p for p in ISSUE_LIST_ROOT.iterdir() if p.is_dir()]
        date_dirs.sort(key=lambda p: p.name, reverse=True)
        for d in date_dirs:
            cand = sorted(d.glob(f"*{suffix}.json"), key=lambda p: p.name, reverse=True)
            if cand:
                return cand[0]
    except Exception:
        return None
    return None


def _extract_json_array(text: str) -> List[Dict[str, Any]]:
    """ëª¨ë¸ ì¶œë ¥ì—ì„œ JSON ë°°ì—´ë§Œ ìµœëŒ€í•œ ë³µêµ¬í•´ì„œ íŒŒì‹±í•œë‹¤."""
    if not text:
        return []
    s = text.strip()

    # ì½”ë“œíœìŠ¤ ì œê±°
    s = re.sub(r"^```(?:json)?\s*", "", s, flags=re.IGNORECASE).strip()
    s = re.sub(r"```\s*$", "", s).strip()

    # 1) ì „ì²´ê°€ JSONì´ë©´ ë°”ë¡œ
    try:
        obj = json.loads(s)
        if isinstance(obj, list):
            return obj
    except Exception:
        pass

    # 2) ë°°ì—´ ë¸”ë¡ë§Œ ì¶”ì¶œ
    l = s.find("[")
    r = s.rfind("]")
    if l != -1 and r != -1 and r > l:
        block = s[l : r + 1]
        try:
            obj = json.loads(block)
            if isinstance(obj, list):
                return obj
        except Exception:
            return []
    return []


def save_issue_list_for_shopping_ai_b_from_a(
    on_progress: Optional[Callable[[Dict[str, Any]], None]] = None,
    *,
    a_path: Optional[str] = None,
    max_titles: int = 220,
    provider: str = "gemini",
    model: str = "gemini-2.0-flash",
) -> Path:
    """
    ìµœì‹ (ë˜ëŠ” ì§€ì •í•œ) _a.jsonì—ì„œ titleë“¤ì„ ëª¨ì•„ AIì—ê²Œ ì „ë‹¬í•˜ê³ ,
    'ì´ìŠˆì™€ ì—°ê´€í•´ ë§¤ì¶œì„ ê¸°ëŒ€í•  ìˆ˜ ìˆëŠ” ìƒí’ˆ í›„ë³´' ë¦¬ìŠ¤íŠ¸ë¥¼ _b.jsonìœ¼ë¡œ ì €ì¥í•œë‹¤.

    ì €ì¥ ìµœì†Œ í¬ë§·:
      { "source": "ai", "title": "...", "rank": 1, "url": null }
    """

    def _prog(msg: str, stage: str = "info"):
        if callable(on_progress):
            try:
                on_progress({"stage": stage, "msg": msg})
            except Exception:
                pass

    # a íŒŒì¼ ê²°ì •
    a_file = Path(a_path) if a_path else _find_latest_issue_list_file("_a")
    if not a_file or (not a_file.exists()):
        raise FileNotFoundError("(_a) ì´ìŠˆ ë¦¬ìŠ¤íŠ¸ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë¨¼ì € 1ë‹¨ê³„ë¡œ _a.jsonì„ ìƒì„±í•˜ì„¸ìš”.")

    _prog(f"AI ë¶„ì„ ëŒ€ìƒ(_a) ë¡œë“œ: {a_file}", stage="load")
    raw = json.loads(a_file.read_text(encoding="utf-8"))
    if not isinstance(raw, list):
        raise ValueError("(_a) JSON êµ¬ì¡°ê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹™ë‹ˆë‹¤.")

    titles = []
    for it in raw:
        if isinstance(it, dict):
            t = (it.get("title") or "").strip()
            if t:
                titles.append(t)

    # ì¤‘ë³µ ì œê±°(ìˆœì„œ ìœ ì§€)
    seen = set()
    uniq = []
    for t in titles:
        if t in seen:
            continue
        seen.add(t)
        uniq.append(t)
    titles = uniq[:max_titles]

    if not titles:
        raise ValueError("(_a)ì—ì„œ titleì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    _prog(f"AIì— ì „ë‹¬í•  title ê°œìˆ˜: {len(titles)}", stage="prep")

    # Gemini í˜¸ì¶œë¶€ëŠ” í”„ë¡œì íŠ¸ì— ì´ë¯¸ ìˆëŠ” AI ë˜í¼(lyrics_gen.py)ë¥¼ ê·¸ëŒ€ë¡œ ì°¸ì¡°
    try:
        from app.utils import AI, AIConfig
    except Exception as e:
        raise RuntimeError(f"Gemini ìš”ì²­(AI) ì½”ë“œ(app.lyrics_gen)ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}")

    cfg = AIConfig(provider=provider, gemini_model=model)
    ai = AI(cfg=cfg)

    system = (
        "ë„ˆëŠ” 15ë…„ì°¨ ì‡¼í•‘ì‡¼ì¸  ì „ë¬¸ê°€ë‹¤. "
        "ì‚¬ëŒë“¤ì˜ ê´€ì‹¬ì„ ëŒê³ , ì‡¼ì¸ ë¡œ ìƒí’ˆì„ ì†Œê°œí–ˆì„ ë•Œ ì‹¤ì œ ë§¤ì¶œë¡œ ì´ì–´ì§ˆ ê°€ëŠ¥ì„±ì´ ìˆëŠ” ìƒí’ˆì„ ì°¾ì•„ë‚´ëŠ” ëŠ¥ë ¥ì´ íƒì›”í•˜ë‹¤."
    )

    bullet = "\n".join([f"- {t}" for t in titles])
    prompt = (
        "ì•„ë˜ëŠ” ìµœê·¼ ì´ìŠˆì˜ ì œëª© ëª©ë¡ì´ë‹¤.\n\n"
        f"{bullet}\n\n"
        "ìš”ì²­: ì´ ì œëª©ë“¤ê³¼ ì—°ê´€í•˜ì—¬ ì‡¼í•‘ì‡¼ì¸ ë¡œ ìƒí’ˆì„ ì˜¬ë ¸ì„ ë•Œ ë§¤ì¶œì„ ê¸°ëŒ€í•  ìˆ˜ ìˆëŠ” 'ìƒí’ˆ/ì•„ì´í…œ/í‚¤ì›Œë“œ' í›„ë³´ë§Œ ê³¨ë¼ë¼.\n"
        "ë¶ˆê°€ëŠ¥í•˜ê±°ë‚˜ ì• ë§¤í•œ ê²ƒì€ ê³¼ê°íˆ ì œì™¸í•´ë¼.\n"
        "ì¶œë ¥ í˜•ì‹: JSON ë°°ì—´ë§Œ ì¶œë ¥í•´ë¼. ê° ì›ì†ŒëŠ” ë‹¤ìŒ ìµœì†Œ í•„ë“œë¥¼ í¬í•¨í•œë‹¤:\n"
        "- source: ë°˜ë“œì‹œ 'ai'\n"
        "- title: ìƒí’ˆ/ì•„ì´í…œ/í‚¤ì›Œë“œ í›„ë³´(ì§§ê³  ëª…í™•)\n"
        "- rank: 1ë¶€í„° ì¦ê°€\n"
        "- url: null\n"
        "ê°€ëŠ¥í•˜ë©´ extraì— products(ë¦¬ìŠ¤íŠ¸), reason(ì§§ì€ ê·¼ê±°), confidence('ìƒ/ì¤‘/í•˜')ë¥¼ ë„£ì–´ë¼.\n"
        "JSON ì™¸ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆë¼."
    )

    _prog("AI ë¶„ì„ ìš”ì²­ ì‹œì‘...", stage="ai")
    out_text = ai.ask_smart(system, prompt, prefer="gemini", allow_fallback=False, trace=False)


    _prog("AI ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ. JSON íŒŒì‹± ì¤‘...", stage="ai")
    items = _extract_json_array(out_text)
    if not items:
        _prog("AI ì‘ë‹µì—ì„œ JSON ë°°ì—´ì„ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥í•©ë‹ˆë‹¤.", stage="warn")
        items = []

    # ìŠ¤í‚¤ë§ˆ ì •ë¦¬ + rank
    cleaned: List[Dict[str, Any]] = []
    for it in items:
        if not isinstance(it, dict):
            continue
        title = (it.get("title") or "").strip()
        if not title:
            continue

        row = {"source": "ai", "title": title, "rank": 0, "url": None}
        extra = it.get("extra")
        if isinstance(extra, dict) and extra:
            row["extra"] = extra
        cleaned.append(row)

    # ì¤‘ë³µ ì œê±° + rank
    seen2 = set()
    final = []
    for it in cleaned:
        k = it["title"]
        if k in seen2:
            continue
        seen2.add(k)
        final.append(it)

    for i, it in enumerate(final, start=1):
        it["rank"] = i

    # ì €ì¥(_b)
    now = datetime.now()
    date_dir = ISSUE_LIST_ROOT / now.strftime("%Y%m%d")
    date_dir.mkdir(parents=True, exist_ok=True)
    b_path = date_dir / f"{now.strftime('%H%M%S')}_b.json"
    b_path.write_text(json.dumps(final, ensure_ascii=False, indent=2), encoding="utf-8")

    _prog(f"AI ìƒí’ˆ í›„ë³´ ë¦¬ìŠ¤íŠ¸(_b) ì €ì¥ ì™„ë£Œ: {b_path}", stage="save")
    return b_path
