# -*- coding: utf-8 -*-
from __future__ import annotations

from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Callable, Optional
import json
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
ISSUE_LIST_ROOT = Path(r"C:\my_games\shorts_make\issue_list")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì™¸ë¶€ ì†ŒìŠ¤ ëª¨ë“ˆ ì„í¬íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ìœ íŠœë¸Œ / Reddit / ì¿ íŒ¡ ìŠ¤í…
try:
    from app.shopping_sources import (
        collect_youtube_shopping_trends,
        collect_reddit_shopping_trends,
        collect_coupang_best_and_rising,
    )
except Exception:
    # ë¬¸ì œê°€ ë‚˜ë”ë¼ë„ ì „ì²´ê°€ ì£½ì§€ ì•Šë„ë¡ ì•ˆì „í•œ ë”ë¯¸ í•¨ìˆ˜ ì œê³µ
    def collect_youtube_shopping_trends(max_items: int = 50) -> List[Dict[str, Any]]:
        return []

    def collect_reddit_shopping_trends(max_items: int = 50) -> List[Dict[str, Any]]:
        return []

    def collect_coupang_best_and_rising(max_items: int = 50) -> List[Dict[str, Any]]:
        return []

# ë„¤ì´ë²„ ì¶”ê°€ ì¹´í…Œê³ ë¦¬ + ì—°í•©ë‰´ìŠ¤ íŠ¸ë Œë“œ
try:
    from app.blog_trend_search_page import (
        get_naver_news_multi_category_topics,
        get_yonhap_news_trend_topics,
    )
except Exception:
    # blog_trend_search_page ë¥¼ ëª» ë¶ˆëŸ¬ì˜¤ë”ë¼ë„ ì „ì²´ê°€ ì£½ì§€ ì•Šê²Œ ë”ë¯¸ í•¨ìˆ˜
    def get_naver_news_multi_category_topics(max_items_per_category: int = 30) -> List[Dict[str, Any]]:
        return []

    def get_yonhap_news_trend_topics(max_items_per_category: int = 30) -> List[Dict[str, Any]]:
        return []


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Selenium (ë„¤ì´ë²„ ë‰´ìŠ¤ ê¸°ë³¸ ë­í‚¹/ê²½ì œ ìš©)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _create_driver():
    """
    Selenium Chrome ë“œë¼ì´ë²„ ìƒì„± (headless).
    - ì´ ëª¨ë“ˆ ì•ˆì—ì„œë§Œ ì‚¬ìš©.
    """


    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument(
        "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/120.0 Safari/537.36"
    )

    driver = webdriver.Chrome(
        service=Service(ChromeDriverManager().install()),
        options=options,
    )
    return driver


def _scrape_naver_news_titles(driver, url: str, limit: int = 50) -> List[str]:
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ ë­í‚¹/ê²½ì œ ì„¹ì…˜ ë“±ì—ì„œ ê¸°ì‚¬ ì œëª© ì¶”ì¶œ.
    - ì—¬ëŸ¬ CSS í›„ë³´ë¥¼ ëŒë©´ì„œ ìµœëŒ€í•œ í…ìŠ¤íŠ¸ë¥¼ ë½‘ëŠ”ë‹¤.
    """


    driver.get(url)

    try:
        WebDriverWait(driver, 15).until(
            EC.presence_of_all_elements_located((By.CSS_SELECTOR, "body"))
        )
    except Exception:
        pass

    html = driver.page_source
    soup = BeautifulSoup(html, "html.parser")

    titles_raw: List[str] = []

    # 1ì°¨: ì¼ë°˜ ê¸°ì‚¬ ë§í¬ íŒ¨í„´
    for a in soup.select("a[href*='/read?']"):
        text = (a.get_text() or "").strip()
        if not text:
            continue
        if len(text) < 8 or len(text) > 80:
            continue
        titles_raw.append(text)

    # 2ì°¨: ë­í‚¹/ë¦¬ìŠ¤íŠ¸ ì „ìš© í´ë˜ìŠ¤ í›„ë³´ë“¤ (ë„¤ì´ë²„ êµ¬ì¡° ë³€ê²½ ëŒ€ë¹„)
    css_candidates = [
        "a.rankingnews_link",                # ë­í‚¹ë‰´ìŠ¤ ì œëª©
        "ol.ranking_list a",                 # ë­í‚¹ ë¦¬ìŠ¤íŠ¸
        "div.list_body a",                   # ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸
        "a[class*='cluster_text_headline']", # í´ëŸ¬ìŠ¤í„° í—¤ë“œë¼ì¸
        "a[class*='list_title']",            # ë¦¬ìŠ¤íŠ¸ ì œëª©
        "a[class*='sa_text_title']",         # ê²€ìƒ‰/ì„¹ì…˜ ì œëª©
    ]
    for css in css_candidates:
        for a in soup.select(css):
            text = (a.get_text() or "").strip()
            if not text:
                continue
            if len(text) < 8 or len(text) > 80:
                continue
            titles_raw.append(text)

    # ì¤‘ë³µ ì œê±° + limit
    seen = set()
    titles: List[str] = []
    for t in titles_raw:
        if t in seen:
            continue
        seen.add(t)
        titles.append(t)
        if len(titles) >= limit:
            break

    print(f"âœ… [NAVER NEWS] {url} ì œëª© {len(titles)}ê°œ ì¶”ì¶œ")
    return titles


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) ë„¤ì´ë²„ ì „ìš© (ë­í‚¹ + ê²½ì œ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def collect_raw_topics_for_shopping_naver(
    on_progress: Optional[Callable[[Dict[str, Any]], None]] = None,
) -> List[Dict[str, Any]]:
    """
    [1ë‹¨ê³„ ì „ìš©]
    - ë„¤ì´ë²„ ë‰´ìŠ¤ ë­í‚¹
    - ë„¤ì´ë²„ ê²½ì œ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸

    ë§Œ ëª¨ì•„ì„œ "ì‡¼í•‘/ì´ìŠˆìš© ì›ì‹œ í† í”½ í’€"ì„ ë§Œë“ ë‹¤.
    (AI íŒë‹¨ì€ ì—¬ê¸°ì„œ í•˜ì§€ ì•ŠìŒ)
    """

    def _prog(msg: str, stage: str = "info"):
        if callable(on_progress):
            try:
                on_progress({"stage": stage, "msg": msg})
            except Exception:
                pass

    topics: List[Dict[str, Any]] = []
    driver = None

    rank_titles: List[str] = []
    econ_titles: List[str] = []

    try:
        _prog("ë„¤ì´ë²„ í¬ë¡¬ ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì¤‘...", stage="init")
        driver = _create_driver()

        # 1) ë„¤ì´ë²„ ë‰´ìŠ¤ ë­í‚¹
        _prog("ë„¤ì´ë²„ ë‰´ìŠ¤ ë­í‚¹ ì œëª© ìˆ˜ì§‘ ì‹œì‘", stage="news_rank")
        rank_url = "https://news.naver.com/main/ranking/popularDay.naver?mid=etc&sid1=111"
        rank_titles = _scrape_naver_news_titles(driver, rank_url, limit=50)
        for idx, title in enumerate(rank_titles, start=1):
            topics.append(
                {
                    "source": "naver_news_rank",
                    "title": title,
                    "rank": idx,
                    "url": None,
                }
            )

        # 2) ë„¤ì´ë²„ ê²½ì œ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
        _prog("ë„¤ì´ë²„ ê²½ì œ ë‰´ìŠ¤ ì œëª© ìˆ˜ì§‘ ì‹œì‘", stage="news_econ")
        econ_url = "https://news.naver.com/main/list.naver?mode=LSD&mid=sec&sid1=101"
        econ_titles = _scrape_naver_news_titles(driver, econ_url, limit=50)
        for idx, title in enumerate(econ_titles, start=1):
            topics.append(
                {
                    "source": "naver_news_economy",
                    "title": title,
                    "rank": idx,
                    "url": None,
                }
            )

    except Exception as e:
        _prog(f"ë„¤ì´ë²„ ì´ìŠˆ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}", stage="error")
        print(f"âš  ë„¤ì´ë²„ ì´ìŠˆ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

    finally:
        if driver is not None:
            try:
                driver.quit()
            except Exception:
                pass

    total = len(topics)
    msg_detail = (
        f"ë„¤ì´ë²„ ë‰´ìŠ¤ ë­í‚¹ {len(rank_titles)}ê°œ, "
        f"ê²½ì œ ë‰´ìŠ¤ {len(econ_titles)}ê°œ, ì´ {total}ê°œ ìˆ˜ì§‘ ì™„ë£Œ"
    )
    _prog(msg_detail, stage="done")
    print(f"ğŸ§© {msg_detail}")
    return topics


def save_issue_list_for_shopping_naver(
    on_progress: Optional[Callable[[Dict[str, Any]], None]] = None,
) -> Path:
    """
    ë„¤ì´ë²„ ê¸°ë°˜ ì‡¼í•‘/ì´ìŠˆ í† í”½ë“¤ì„ ëª¨ì•„ì„œ
    C:\\my_games\\shorts_make\\issue_list\\YYYYMMDD\\HHMMSS.json ìœ¼ë¡œ ì €ì¥í•œë‹¤.
    """
    topics = collect_raw_topics_for_shopping_naver(on_progress=on_progress)

    now = datetime.now()
    date_dir = ISSUE_LIST_ROOT / now.strftime("%Y%m%d")
    date_dir.mkdir(parents=True, exist_ok=True)

    file_path = date_dir / f"{now.strftime('%H%M%S')}.json"

    with file_path.open("w", encoding="utf-8") as f:
        json.dump(topics, f, ensure_ascii=False, indent=2)

    msg = f"ë„¤ì´ë²„ ì´ìŠˆ ë¦¬ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: {file_path}"
    if callable(on_progress):
        try:
            on_progress({"stage": "save", "msg": msg})
        except Exception:
            pass

    print(f"ğŸ’¾ {msg}")
    return file_path


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) ì „ì²´ ì‡¼í•‘ ì´ìŠˆ (ë„¤ì´ë²„ + ë„¤ì´ë²„ì¶”ê°€ + ì¿ íŒ¡ìŠ¤í… + ìœ íŠœë¸Œ + Reddit + ì—°í•©ë‰´ìŠ¤)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def collect_raw_topics_for_shopping_all(
    on_progress: Optional[Callable[[Dict[str, Any]], None]] = None,
) -> List[Dict[str, Any]]:
    """
    [1ë‹¨ê³„ í™•ì¥ ë²„ì „]

    - ë„¤ì´ë²„ ì´ìŠˆ(ë‰´ìŠ¤ ë­í‚¹ + ê²½ì œ)
    - ë„¤ì´ë²„ ì¶”ê°€ ì¹´í…Œê³ ë¦¬(ì‚¬íšŒ/ìƒí™œ/IT)  â† blog_trend_search_page.get_naver_news_multi_category_topics
    - ì¿ íŒ¡ BEST/ê¸‰ìƒìŠ¹ (í˜„ì¬ëŠ” ìŠ¤í…: í•­ìƒ ë¹ˆ ë¦¬ìŠ¤íŠ¸)
    - ìœ íŠœë¸Œ ì‡¼í•‘/ë¦¬ë·°/ì‡¼ì¸  íŠ¸ë Œë“œ
    - í•´ì™¸ ì‡¼í•‘ íŠ¸ë Œë“œ(Reddit)
    - ì—°í•©ë‰´ìŠ¤ íŠ¸ë Œë“œ/í•«/ìƒí™œ/ê²½ì œ/IT

    ë¥¼ ì „ë¶€ í•©ì³ì„œ "ì‡¼í•‘/ì´ìŠˆìš© ì›ì‹œ í† í”½ í’€"ì„ ë§Œë“ ë‹¤.
    (AI íŒë‹¨/í•„í„°ë§ì€ ì—¬ê¸°ì„œ í•˜ì§€ ì•ŠìŒ)
    """

    def _prog(msg: str, stage: str = "info") -> None:
        if callable(on_progress):
            try:
                on_progress({"stage": stage, "msg": msg})
            except Exception:
                pass

    topics: List[Dict[str, Any]] = []

    naver_topics: List[Dict[str, Any]] = []
    naver_extra_topics: List[Dict[str, Any]] = []
    coupang_topics: List[Dict[str, Any]] = []
    yt_topics: List[Dict[str, Any]] = []
    rd_topics: List[Dict[str, Any]] = []
    yonhap_topics: List[Dict[str, Any]] = []

    # 1) ë„¤ì´ë²„ ê¸°ë³¸(ë­í‚¹/ê²½ì œ)
    try:
        _prog("ë„¤ì´ë²„ ì´ìŠˆ(ë‰´ìŠ¤ ë­í‚¹/ê²½ì œ) ìˆ˜ì§‘ ì‹œì‘", stage="naver")
        naver_topics = collect_raw_topics_for_shopping_naver(on_progress=on_progress)
        topics.extend(naver_topics)
    except Exception as e:
        _prog(f"ë„¤ì´ë²„ ì´ìŠˆ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}", stage="error")
        print(f"âš  ë„¤ì´ë²„ ì´ìŠˆ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

    # 1-ì¶”ê°€) ë„¤ì´ë²„ ì¶”ê°€ ì¹´í…Œê³ ë¦¬(ì‚¬íšŒ/ìƒí™œ/IT) â€“ blog_trend_search_page ì‚¬ìš©
    try:
        _prog("ë„¤ì´ë²„ ì¶”ê°€ ì¹´í…Œê³ ë¦¬(ì‚¬íšŒ/ìƒí™œ/IT) ìˆ˜ì§‘ ì‹œì‘", stage="naver_extra")
        naver_extra_topics = get_naver_news_multi_category_topics(max_items_per_category=30)
        topics.extend(naver_extra_topics)
        _prog(f"ë„¤ì´ë²„ ì¶”ê°€ ì¹´í…Œê³ ë¦¬ í† í”½ {len(naver_extra_topics)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ", stage="naver_extra")
    except Exception as e:
        _prog(f"ë„¤ì´ë²„ ì¶”ê°€ ì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}", stage="error")
        print(f"âš  ë„¤ì´ë²„ ì¶”ê°€ ì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

    # 2) ì¿ íŒ¡ BEST/ê¸‰ìƒìŠ¹ (í˜„ì¬ëŠ” ìŠ¤í…: í•­ìƒ []).
    try:
        _prog("ì¿ íŒ¡ BEST/ê¸‰ìƒìŠ¹(ìŠ¤í…) ìˆ˜ì§‘ ì‹œì‘", stage="coupang")
        coupang_topics = collect_coupang_best_and_rising(max_items=50)
        topics.extend(coupang_topics)
        _prog(f"ì¿ íŒ¡ íŠ¸ë Œë“œ í† í”½ {len(coupang_topics)}ê°œ ìˆ˜ì§‘ (í˜„ì¬ ìŠ¤í…)", stage="coupang")
    except Exception as e:
        _prog(f"ì¿ íŒ¡ íŠ¸ë Œë“œ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}", stage="error")
        print(f"âš  ì¿ íŒ¡ íŠ¸ë Œë“œ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

    # 3) ìœ íŠœë¸Œ ì‡¼í•‘/ì‡¼ì¸  íŠ¸ë Œë“œ
    try:
        _prog("ìœ íŠœë¸Œ ì‡¼í•‘/ì‡¼ì¸  íŠ¸ë Œë“œ ìˆ˜ì§‘ ì‹œì‘", stage="youtube")
        yt_topics = collect_youtube_shopping_trends(max_items=50)
        topics.extend(yt_topics)
        _prog(f"ìœ íŠœë¸Œ ì‡¼í•‘/ì‡¼ì¸  í† í”½ {len(yt_topics)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ", stage="youtube")
    except Exception as e:
        _prog(f"ìœ íŠœë¸Œ ì‡¼í•‘ íŠ¸ë Œë“œ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}", stage="error")
        print(f"âš  ìœ íŠœë¸Œ ì‡¼í•‘ íŠ¸ë Œë“œ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

    # 4) í•´ì™¸ ì‡¼í•‘ íŠ¸ë Œë“œ(Reddit)
    try:
        _prog("í•´ì™¸ ì‡¼í•‘ íŠ¸ë Œë“œ(Reddit) ìˆ˜ì§‘ ì‹œì‘", stage="reddit")
        rd_topics = collect_reddit_shopping_trends(max_items=50)
        topics.extend(rd_topics)
        _prog(f"Reddit ì‡¼í•‘ í† í”½ {len(rd_topics)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ", stage="reddit")
    except Exception as e:
        _prog(f"Reddit ì‡¼í•‘ íŠ¸ë Œë“œ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}", stage="error")
        print(f"âš  Reddit ì‡¼í•‘ íŠ¸ë Œë“œ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

    # 5) ì—°í•©ë‰´ìŠ¤ íŠ¸ë Œë“œ(ì¸ê¸°/í•«/ìƒí™œ/ê²½ì œ/IT)
    try:
        _prog("ì—°í•©ë‰´ìŠ¤ íŠ¸ë Œë“œ ìˆ˜ì§‘ ì‹œì‘", stage="yonhap")
        yonhap_topics = get_yonhap_news_trend_topics(max_items_per_category=30)
        topics.extend(yonhap_topics)
        _prog(f"ì—°í•©ë‰´ìŠ¤ íŠ¸ë Œë“œ í† í”½ {len(yonhap_topics)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ", stage="yonhap")
    except Exception as e:
        _prog(f"ì—°í•©ë‰´ìŠ¤ íŠ¸ë Œë“œ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}", stage="error")
        print(f"âš  ì—°í•©ë‰´ìŠ¤ íŠ¸ë Œë“œ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

    total = len(topics)
    summary = (
        f"ë„¤ì´ë²„(ê¸°ë³¸) {len(naver_topics)}ê°œ, "
        f"ë„¤ì´ë²„(ì¶”ê°€) {len(naver_extra_topics)}ê°œ, "
        f"ì¿ íŒ¡ {len(coupang_topics)}ê°œ, "
        f"ìœ íŠœë¸Œ {len(yt_topics)}ê°œ, "
        f"Reddit {len(rd_topics)}ê°œ, "
        f"ì—°í•©ë‰´ìŠ¤ {len(yonhap_topics)}ê°œ â†’ ì´ {total}ê°œ ìˆ˜ì§‘ ì™„ë£Œ"
    )
    _prog(summary, stage="done")
    print(f"ğŸ§© {summary}")
    return topics


def save_issue_list_for_shopping_all(
    on_progress: Optional[Callable[[Dict[str, Any]], None]] = None,
) -> Path:
    """
    ë„¤ì´ë²„ + ë„¤ì´ë²„ì¶”ê°€ + ìœ íŠœë¸Œ + Reddit(+ì¿ íŒ¡ ìŠ¤í…) + ì—°í•©ë‰´ìŠ¤ ê¸°ë°˜
    ì‡¼í•‘/ì´ìŠˆ í† í”½ë“¤ì„ ëª¨ì•„ì„œ
    C:\\my_games\\shorts_make\\issue_list\\YYYYMMDD\\HHMMSS.json ìœ¼ë¡œ ì €ì¥í•œë‹¤.
    """
    topics = collect_raw_topics_for_shopping_all(on_progress=on_progress)

    now = datetime.now()
    date_dir = ISSUE_LIST_ROOT / now.strftime("%Y%m%d")
    date_dir.mkdir(parents=True, exist_ok=True)

    file_path = date_dir / f"{now.strftime('%H%M%S')}.json"

    with file_path.open("w", encoding="utf-8") as f:
        json.dump(topics, f, ensure_ascii=False, indent=2)

    msg = f"ì „ì²´ ì‡¼í•‘ ì´ìŠˆ ë¦¬ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: {file_path}"
    if callable(on_progress):
        try:
            on_progress({"stage": "save", "msg": msg})
        except Exception:
            pass

    print(f"ğŸ’¾ {msg}")
    return file_path


